{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXJOdzIXQu0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d9920b7-3a47-46fa-96fc-35f8fb91d329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.transforms import ToTensor\n",
        "from pandas import Series\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from torch.utils.data import DataLoader\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA = pd.read_parquet('/content/drive/My Drive/MasterProject/create_data_my_model_add_label_4_lr_0.1_inculde_networks.parquet')\n",
        "DATA = pd.read_parquet('/content/drive/My Drive/MasterProject/create_data_my_model_add_label_5_lr_0.03_inculde_networks.parquet')\n",
        "DATA.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "nG_SSGVaGdM-",
        "outputId": "3357af5c-3341-4065-bd57-49bdd94e39bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ambient_avg  ambient_std  ambient_min  ambient_max  dimm0_temp_avg  \\\n",
              "0    22.632605     0.082797    22.509747    22.685978       30.431459   \n",
              "1    22.635746     0.083260    22.511705    22.689707       30.434170   \n",
              "2    22.638121     0.084007    22.515509    22.694950       30.438974   \n",
              "3    22.636614     0.083642    22.515266    22.696047       30.436201   \n",
              "4    22.636734     0.083944    22.516420    22.699638       30.436991   \n",
              "\n",
              "   dimm0_temp_std  dimm0_temp_min  dimm0_temp_max  dimm10_temp_avg  \\\n",
              "0        0.138977       30.166260       30.585276        30.848211   \n",
              "1        0.138600       30.169426       30.589201        30.851128   \n",
              "2        0.139176       30.173515       30.597065        30.856789   \n",
              "3        0.138888       30.173256       30.596045        30.855408   \n",
              "4        0.139211       30.175510       30.597576        30.854156   \n",
              "\n",
              "   dimm10_temp_std  ...  avg_gpu3_core_temp_max  std_gpu3_core_temp_max  \\\n",
              "0         0.136500  ...               44.083305                6.958302   \n",
              "1         0.136243  ...               44.083694                6.961399   \n",
              "2         0.135928  ...               44.093174                6.962402   \n",
              "3         0.135764  ...               44.086926                6.957322   \n",
              "4         0.135490  ...               44.097366                6.955503   \n",
              "\n",
              "   min_gpu3_core_temp_max  max_gpu3_core_temp_max  avg_ps0_input_power_min  \\\n",
              "0               36.521801               53.254215               341.266022   \n",
              "1               36.526020               53.262257               341.346680   \n",
              "2               36.531658               53.275291               341.457275   \n",
              "3               36.531876               53.266701               341.443573   \n",
              "4               36.543251               53.277370               341.487854   \n",
              "\n",
              "   std_ps0_input_power_min  min_ps0_input_power_min  max_ps0_input_power_min  \\\n",
              "0                75.682755               257.505951               442.272919   \n",
              "1                75.735840               257.599915               442.455353   \n",
              "2                75.766037               257.665527               442.639343   \n",
              "3                75.814156               257.640503               442.686920   \n",
              "4                75.797501               257.715240               442.693054   \n",
              "\n",
              "   next_value                 timestamp  \n",
              "0    0.017987 2021-04-02 00:45:00+00:00  \n",
              "1    0.017967 2021-04-02 01:00:00+00:00  \n",
              "2    0.017918 2021-04-02 01:15:00+00:00  \n",
              "3    0.019866 2021-04-02 01:30:00+00:00  \n",
              "4    0.019795 2021-04-02 01:45:00+00:00  \n",
              "\n",
              "[5 rows x 1383 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-43fd87c0-73ab-4e47-ad48-957e0b43b334\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ambient_avg</th>\n",
              "      <th>ambient_std</th>\n",
              "      <th>ambient_min</th>\n",
              "      <th>ambient_max</th>\n",
              "      <th>dimm0_temp_avg</th>\n",
              "      <th>dimm0_temp_std</th>\n",
              "      <th>dimm0_temp_min</th>\n",
              "      <th>dimm0_temp_max</th>\n",
              "      <th>dimm10_temp_avg</th>\n",
              "      <th>dimm10_temp_std</th>\n",
              "      <th>...</th>\n",
              "      <th>avg_gpu3_core_temp_max</th>\n",
              "      <th>std_gpu3_core_temp_max</th>\n",
              "      <th>min_gpu3_core_temp_max</th>\n",
              "      <th>max_gpu3_core_temp_max</th>\n",
              "      <th>avg_ps0_input_power_min</th>\n",
              "      <th>std_ps0_input_power_min</th>\n",
              "      <th>min_ps0_input_power_min</th>\n",
              "      <th>max_ps0_input_power_min</th>\n",
              "      <th>next_value</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22.632605</td>\n",
              "      <td>0.082797</td>\n",
              "      <td>22.509747</td>\n",
              "      <td>22.685978</td>\n",
              "      <td>30.431459</td>\n",
              "      <td>0.138977</td>\n",
              "      <td>30.166260</td>\n",
              "      <td>30.585276</td>\n",
              "      <td>30.848211</td>\n",
              "      <td>0.136500</td>\n",
              "      <td>...</td>\n",
              "      <td>44.083305</td>\n",
              "      <td>6.958302</td>\n",
              "      <td>36.521801</td>\n",
              "      <td>53.254215</td>\n",
              "      <td>341.266022</td>\n",
              "      <td>75.682755</td>\n",
              "      <td>257.505951</td>\n",
              "      <td>442.272919</td>\n",
              "      <td>0.017987</td>\n",
              "      <td>2021-04-02 00:45:00+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22.635746</td>\n",
              "      <td>0.083260</td>\n",
              "      <td>22.511705</td>\n",
              "      <td>22.689707</td>\n",
              "      <td>30.434170</td>\n",
              "      <td>0.138600</td>\n",
              "      <td>30.169426</td>\n",
              "      <td>30.589201</td>\n",
              "      <td>30.851128</td>\n",
              "      <td>0.136243</td>\n",
              "      <td>...</td>\n",
              "      <td>44.083694</td>\n",
              "      <td>6.961399</td>\n",
              "      <td>36.526020</td>\n",
              "      <td>53.262257</td>\n",
              "      <td>341.346680</td>\n",
              "      <td>75.735840</td>\n",
              "      <td>257.599915</td>\n",
              "      <td>442.455353</td>\n",
              "      <td>0.017967</td>\n",
              "      <td>2021-04-02 01:00:00+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22.638121</td>\n",
              "      <td>0.084007</td>\n",
              "      <td>22.515509</td>\n",
              "      <td>22.694950</td>\n",
              "      <td>30.438974</td>\n",
              "      <td>0.139176</td>\n",
              "      <td>30.173515</td>\n",
              "      <td>30.597065</td>\n",
              "      <td>30.856789</td>\n",
              "      <td>0.135928</td>\n",
              "      <td>...</td>\n",
              "      <td>44.093174</td>\n",
              "      <td>6.962402</td>\n",
              "      <td>36.531658</td>\n",
              "      <td>53.275291</td>\n",
              "      <td>341.457275</td>\n",
              "      <td>75.766037</td>\n",
              "      <td>257.665527</td>\n",
              "      <td>442.639343</td>\n",
              "      <td>0.017918</td>\n",
              "      <td>2021-04-02 01:15:00+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>22.636614</td>\n",
              "      <td>0.083642</td>\n",
              "      <td>22.515266</td>\n",
              "      <td>22.696047</td>\n",
              "      <td>30.436201</td>\n",
              "      <td>0.138888</td>\n",
              "      <td>30.173256</td>\n",
              "      <td>30.596045</td>\n",
              "      <td>30.855408</td>\n",
              "      <td>0.135764</td>\n",
              "      <td>...</td>\n",
              "      <td>44.086926</td>\n",
              "      <td>6.957322</td>\n",
              "      <td>36.531876</td>\n",
              "      <td>53.266701</td>\n",
              "      <td>341.443573</td>\n",
              "      <td>75.814156</td>\n",
              "      <td>257.640503</td>\n",
              "      <td>442.686920</td>\n",
              "      <td>0.019866</td>\n",
              "      <td>2021-04-02 01:30:00+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>22.636734</td>\n",
              "      <td>0.083944</td>\n",
              "      <td>22.516420</td>\n",
              "      <td>22.699638</td>\n",
              "      <td>30.436991</td>\n",
              "      <td>0.139211</td>\n",
              "      <td>30.175510</td>\n",
              "      <td>30.597576</td>\n",
              "      <td>30.854156</td>\n",
              "      <td>0.135490</td>\n",
              "      <td>...</td>\n",
              "      <td>44.097366</td>\n",
              "      <td>6.955503</td>\n",
              "      <td>36.543251</td>\n",
              "      <td>53.277370</td>\n",
              "      <td>341.487854</td>\n",
              "      <td>75.797501</td>\n",
              "      <td>257.715240</td>\n",
              "      <td>442.693054</td>\n",
              "      <td>0.019795</td>\n",
              "      <td>2021-04-02 01:45:00+00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1383 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43fd87c0-73ab-4e47-ad48-957e0b43b334')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-43fd87c0-73ab-4e47-ad48-957e0b43b334 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-43fd87c0-73ab-4e47-ad48-957e0b43b334');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-acb8fa6b-fb49-4672-82a1-ab182dcf4365\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-acb8fa6b-fb49-4672-82a1-ab182dcf4365')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-acb8fa6b-fb49-4672-82a1-ab182dcf4365 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "DATA"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiFEl64MUX7u"
      },
      "outputs": [],
      "source": [
        "#The dataset has periods of unavailability of Nagios traces, as described in the dataset paper:  https://www.nature.com/articles/s41597-023-02174-3/figures/3\n",
        "#We suggest dropping the periods where the labels are largely unavailable and using the dataset either after 1.4.2021 or 1.10.2021.\n",
        "DATA = DATA[DATA['timestamp'] > '2021-04-01']\n",
        "\n",
        "### parisa change\n",
        "DATA['value'] = DATA['value'].replace(2,1)\n",
        "DATA['value'] = DATA['value'].replace(3,1)\n",
        "## parisa change"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQkJAI-cNPUG"
      },
      "outputs": [],
      "source": [
        "DATA.reset_index(drop=True, inplace = True)\n",
        "DATA = DATA.fillna(0)\n",
        "DATA['timestamp'] = pd.to_datetime(DATA['timestamp'])\n",
        "l = DATA.timestamp.diff() == pd.Timedelta(minutes=15) #time consistency -> measurements should be 15 minutes apart\n",
        "chunks = []\n",
        "current_chunk = []\n",
        "for index, value in enumerate(l):\n",
        "    current_chunk.append(DATA.iloc[index])\n",
        "    if not value:\n",
        "        chunks.append(pd.DataFrame(current_chunk))\n",
        "        current_chunk = []\n",
        "\n",
        "\n",
        "if current_chunk:\n",
        "    chunks.append(pd.DataFrame(current_chunk))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA['value'] = DATA['value'].replace(2,1)\n",
        "DATA['value'] = DATA['value'].replace(3,1)\n",
        "\n",
        "### parisa change\n",
        "relevant = [c for c in chunks if len(c) >= 20] #assuming time window of 20\n",
        "revelent_len = [len(c) for c in chunks if len(c) >= 20]\n",
        "DATA2 = pd.concat(relevant)\n",
        "DATA = DATA2\n",
        "DATA['value'] = DATA['value'].replace(2,1)\n",
        "DATA['value'] = DATA['value'].replace(3,1)\n",
        "\n",
        "### parisa change end\n",
        "##3 parisa change\n",
        "# relevant = [c for c in chunks if len(c) >= 20] #assuming time window of 20\n",
        "# DATA2 = pd.concat(relevant)\n",
        "# DATA = DATA2\n",
        "# DATA['value'] = DATA['value'].replace(2,1)\n",
        "# DATA['value'] = DATA['value'].replace(3,1)\n",
        "# DATA = DATA.drop(columns=['timestamp'])\n",
        "# DATA = DATA.astype(float)\n",
        "##3 parisa change end"
      ],
      "metadata": {
        "id": "MWVL8xDF579k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA3= DATA\n",
        "DATA=DATA.drop(columns=['timestamp'])\n",
        "DATA = DATA.astype(float)"
      ],
      "metadata": {
        "id": "fpEk6-otzJku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2IMXqzoQu03"
      },
      "outputs": [],
      "source": [
        "scaler = preprocessing.MinMaxScaler()\n",
        "names = DATA.columns\n",
        "d = scaler.fit_transform(DATA)\n",
        "DATA = pd.DataFrame(d, columns=names)\n",
        "### parisa change\n",
        "timestamp_scaler = preprocessing.MinMaxScaler()\n",
        "DATA['timestamp'] = timestamp_scaler.fit_transform(DATA3['timestamp'].astype('int64').values.reshape(-1, 1))\n",
        "#### parisa change end"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA['next_value']=DATA3['next_value']*100/4\n",
        "# DATA['next_value'][0]=0.44665"
      ],
      "metadata": {
        "id": "lEFkKVfoPntn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA"
      ],
      "metadata": {
        "id": "iijabMgLPuxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA.dropna()"
      ],
      "metadata": {
        "id": "KcSIP1fwUiHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### to get rid of time and test\n",
        "# DATA=DATA.drop(columns=['timestamp'])"
      ],
      "metadata": {
        "id": "xrs7Ujb-AEy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJlNWM1tQu03"
      },
      "outputs": [],
      "source": [
        "train_data = DATA[:int(DATA.shape[0]*0.8)]\n",
        "test_data = DATA[int(DATA.shape[0]*0.8):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "VUT7QzOKQu04",
        "outputId": "a3d26606-8200-4947-e1ab-8efaa8c71033"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "value\n",
              "0.449137    2\n",
              "0.488393    2\n",
              "0.400800    2\n",
              "0.404007    2\n",
              "0.317467    2\n",
              "           ..\n",
              "0.282988    1\n",
              "0.283525    1\n",
              "0.282731    1\n",
              "0.281694    1\n",
              "0.417227    1\n",
              "Name: count, Length: 41749, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>value</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.449137</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.488393</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.400800</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.404007</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.317467</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.282988</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.283525</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.282731</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.281694</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.417227</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>41749 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "train_data['value'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onXqoqEGQu04"
      },
      "outputs": [],
      "source": [
        "train_feat = train_data.drop(columns=['value'])\n",
        "train_feat = train_feat.to_numpy()\n",
        "test_feat = test_data.drop(columns=['value'])\n",
        "test_feat = test_feat.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TKEoNSjQu04"
      },
      "outputs": [],
      "source": [
        "train_feat = torch.tensor(train_feat, dtype=torch.float)\n",
        "test_feat = torch.tensor(test_feat, dtype=torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Of6oEPbQu05",
        "outputId": "17a33071-7a5d-45eb-98a3-177cd6edab0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4162, 0.4165, 0.4171,  ..., 0.3144, 0.3110, 0.3088])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "test_labels = test_data['value']\n",
        "test_labels = test_labels.to_numpy()\n",
        "test_labels = torch.tensor(test_labels, dtype=torch.float)\n",
        "test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z95V8uGGQu05"
      },
      "outputs": [],
      "source": [
        "train_window = 20 ## 20\n",
        "\n",
        "def create_data_seq(data,tw):\n",
        "    seq = []\n",
        "    for i in range(len(data)-tw):\n",
        "        x_seq = data[i:i+tw],\n",
        "        y_seq = data[i+tw:i+tw+1]  ###در ترین میاد 0 تا 20 رو میده و میگه 21 رو حدس بزن\n",
        "        seq.append((x_seq,y_seq))\n",
        "    return seq\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQND2EJuQu06"
      },
      "outputs": [],
      "source": [
        "# train_seq = create_data_seq(train_feat,train_window,revelent_len) ## parisa change\n",
        "train_seq = create_data_seq(train_feat,train_window) ## parisa change"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xnsh7J1Qu06"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_seq, batch_size=1, shuffle=True)\n",
        "\n",
        "X,y  = next(iter(train_loader))\n",
        "# print(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dC4Ja5rSQu06"
      },
      "outputs": [],
      "source": [
        "# test_seq = create_data_seq(test_feat,train_window,revelent_len)\n",
        "test_seq = create_data_seq(test_feat,train_window)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxlFxsRtQu06"
      },
      "outputs": [],
      "source": [
        "test_loader = DataLoader(test_seq, batch_size=1, shuffle=False) ## در هر فور ما یه تعدادی بچ داریم که میدیم به دل با بچ بیشتر میتونیم بگیم مثلا 2 تا 2 تا بهش بده\n",
        "X,y = next(iter(test_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeHDksdoLOw3"
      },
      "outputs": [],
      "source": [
        "############### mine for add h,c\n",
        "\n",
        "class encoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # First LSTM layer\n",
        "        self.lstm1 = torch.nn.LSTM(\n",
        "            input_size=1382 ,\n",
        "            hidden_size=32,  # Increased the hidden size for this example\n",
        "            batch_first=True,\n",
        "            num_layers=1\n",
        "        )\n",
        "\n",
        "        # Second LSTM layer\n",
        "        self.lstm2 = torch.nn.LSTM(\n",
        "            input_size=32,   # Input size matches the hidden size of lstm1\n",
        "            hidden_size=16,\n",
        "            batch_first=True,\n",
        "            num_layers=1\n",
        "        )\n",
        "\n",
        "        # Third LSTM layer (newly added)\n",
        "        self.lstm3 = torch.nn.LSTM(\n",
        "            input_size=16,   # Input size matches the hidden size of lstm2\n",
        "            hidden_size=8,\n",
        "            batch_first=True,\n",
        "            num_layers=1\n",
        "        )\n",
        "        self.h_proj_1_to_2 = torch.nn.Linear(32, 16)\n",
        "        self.c_proj_1_to_2 = torch.nn.Linear(32, 16)\n",
        "\n",
        "        self.h_proj_2_to_3 = torch.nn.Linear(16, 8)\n",
        "        self.c_proj_2_to_3 = torch.nn.Linear(16, 8)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        # Initial hidden and cell states for lstm1\n",
        "        # h0 = torch.zeros(1, batch_size, 32).requires_grad_().to(device)\n",
        "        # c0 = torch.zeros(1, batch_size, 32).requires_grad_().to(device)\n",
        "        # x, (_, _) = self.lstm1(x, (h0, c0))\n",
        "\n",
        "        # # Initial hidden and cell states for lstm2\n",
        "        # h0 = torch.zeros(1, batch_size, 16).requires_grad_().to(device)\n",
        "        # c0 = torch.zeros(1, batch_size, 16).requires_grad_().to(device)\n",
        "        # x, (_, _) = self.lstm2(x, (h0, c0))\n",
        "\n",
        "        # # Initial hidden and cell states for lstm3\n",
        "        # h0 = torch.zeros(1, batch_size, 8).requires_grad_().to(device)\n",
        "        # c0 = torch.zeros(1, batch_size, 8).requires_grad_().to(device)\n",
        "        # x, (_, _) = self.lstm3(x, (h0, c0))\n",
        "\n",
        "        ###### parisa changes of model give h , c to new layaer\n",
        "\n",
        "        # Initial hidden and cell states for lstm1\n",
        "        # Initial hidden and cell states for lstm1\n",
        "        h0 = torch.zeros(1, batch_size, 32).to(x.device)\n",
        "        c0 = torch.zeros(1, batch_size, 32).to(x.device)\n",
        "        x, (h1, c1) = self.lstm1(x, (h0, c0))\n",
        "\n",
        "        # Resize h1, c1 to match the input size of lstm2\n",
        "        h1 = self.h_proj_1_to_2(h1)\n",
        "        c1 = self.c_proj_1_to_2(c1)\n",
        "        x, (h2, c2) = self.lstm2(x, (h1, c1))\n",
        "\n",
        "        # Resize h2, c2 to match the input size of lstm3\n",
        "        h2 = self.h_proj_2_to_3(h2)\n",
        "        c2 = self.c_proj_2_to_3(c2)\n",
        "        x, (h3, c3) = self.lstm3(x, (h2, c2))\n",
        "        return x[:, :, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkWYYDUuLOw5"
      },
      "outputs": [],
      "source": [
        "### mine for add h,c\n",
        "class decoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # First LSTM layer (added for symmetry with the encoder)\n",
        "        self.lstm1 = torch.nn.LSTM(\n",
        "            input_size=8,\n",
        "            hidden_size=16,\n",
        "            batch_first=True,\n",
        "            num_layers=1\n",
        "        )\n",
        "\n",
        "        # Second LSTM layer\n",
        "        self.lstm2 = torch.nn.LSTM(\n",
        "            input_size=16,\n",
        "            hidden_size=32,\n",
        "            batch_first=True,\n",
        "            num_layers=1\n",
        "        )\n",
        "\n",
        "        # Third LSTM layer\n",
        "        self.lstm3 = torch.nn.LSTM(\n",
        "            input_size=32,\n",
        "            hidden_size=1382,\n",
        "            batch_first=True,\n",
        "            num_layers=1\n",
        "        )\n",
        "\n",
        "        self.h_proj_1_to_2 = torch.nn.Linear(16, 32)\n",
        "        self.c_proj_1_to_2 = torch.nn.Linear(16, 32)\n",
        "\n",
        "        self.h_proj_2_to_3 = torch.nn.Linear(32, 1382)\n",
        "        self.c_proj_2_to_3 = torch.nn.Linear(32, 1382)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        # # Initial hidden and cell states for lstm1\n",
        "        # h0 = torch.zeros(1, batch_size, 16).requires_grad_().to(device)\n",
        "        # c0 = torch.zeros(1, batch_size, 16).requires_grad_().to(device)\n",
        "        # x, (_, _) = self.lstm1(x, (h0, c0))\n",
        "\n",
        "        # # Initial hidden and cell states for lstm2\n",
        "        # h0 = torch.zeros(1, batch_size, 32).requires_grad_().to(device)\n",
        "        # c0 = torch.zeros(1, batch_size, 32).requires_grad_().to(device)\n",
        "        # x, (_, _) = self.lstm2(x, (h0, c0))\n",
        "\n",
        "        # # Initial hidden and cell states for lstm3\n",
        "        # h0 = torch.zeros(1, batch_size, 352).requires_grad_().to(device)\n",
        "        # c0 = torch.zeros(1, batch_size, 352).requires_grad_().to(device)\n",
        "        # x, (_, _) = self.lstm3(x, (h0, c0))\n",
        "\n",
        "\n",
        "        ###### parisa changes of model give h , c to new layaer\n",
        "\n",
        "        # Initial hidden and cell states for lstm1\n",
        "        h1 = torch.zeros(1, batch_size, 16).to(x.device)\n",
        "        c1 = torch.zeros(1, batch_size, 16).to(x.device)\n",
        "        x, (h1, c1) = self.lstm1(x, (h1, c1))\n",
        "\n",
        "        # Resize h1, c1 to match the input size of lstm2\n",
        "        h2 = self.h_proj_1_to_2(h1)\n",
        "        c2 = self.c_proj_1_to_2(c1)\n",
        "        x, (h2, c2) = self.lstm2(x, (h2, c2))\n",
        "\n",
        "        # Resize h2, c2 to match the input size of lstm3\n",
        "        h3 = self.h_proj_2_to_3(h2)\n",
        "        c3 = self.c_proj_2_to_3(c2)\n",
        "        x, (h3, c3) = self.lstm3(x, (h3, c3))\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKtcGAZu8-5z"
      },
      "outputs": [],
      "source": [
        "### mine\n",
        "class RUAD(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder().to(device)\n",
        "        self.fc1 = torch.nn.Linear(8, 16)\n",
        "        self.fc2 = torch.nn.Linear(16, 8)\n",
        "        self.decoder = decoder().to(device)  # Adding the decoder to RUAD\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        # Passing through the fully connected layers   ----- new changes\n",
        "        # x = self.fc1(x)\n",
        "        # x = self.fc2(x)\n",
        "        # Passing the result through the decoder ------- end of new changes\n",
        "        x = self.decoder(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOfd8fWLQu08"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eZVG4bFQu08",
        "outputId": "ff00b22c-897a-417f-ea7b-52caff90f351"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RUAD(\n",
              "  (encoder): encoder(\n",
              "    (lstm1): LSTM(1382, 32, batch_first=True)\n",
              "    (lstm2): LSTM(32, 16, batch_first=True)\n",
              "    (lstm3): LSTM(16, 8, batch_first=True)\n",
              "    (h_proj_1_to_2): Linear(in_features=32, out_features=16, bias=True)\n",
              "    (c_proj_1_to_2): Linear(in_features=32, out_features=16, bias=True)\n",
              "    (h_proj_2_to_3): Linear(in_features=16, out_features=8, bias=True)\n",
              "    (c_proj_2_to_3): Linear(in_features=16, out_features=8, bias=True)\n",
              "  )\n",
              "  (fc1): Linear(in_features=8, out_features=16, bias=True)\n",
              "  (fc2): Linear(in_features=16, out_features=8, bias=True)\n",
              "  (decoder): decoder(\n",
              "    (lstm1): LSTM(8, 16, batch_first=True)\n",
              "    (lstm2): LSTM(16, 32, batch_first=True)\n",
              "    (lstm3): LSTM(32, 1382, batch_first=True)\n",
              "    (h_proj_1_to_2): Linear(in_features=16, out_features=32, bias=True)\n",
              "    (c_proj_1_to_2): Linear(in_features=16, out_features=32, bias=True)\n",
              "    (h_proj_2_to_3): Linear(in_features=32, out_features=1382, bias=True)\n",
              "    (c_proj_2_to_3): Linear(in_features=32, out_features=1382, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "model = RUAD()\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iL-wSQFNQu08"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.5)  ### adam ro bezar va bebin\n",
        "criterion = torch.nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQEClIx2c8P4",
        "outputId": "499fdd5f-0e47-42a4-81de-92142e257ff1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RUAD(\n",
            "  (encoder): encoder(\n",
            "    (lstm1): LSTM(1382, 32, batch_first=True)\n",
            "    (lstm2): LSTM(32, 16, batch_first=True)\n",
            "    (lstm3): LSTM(16, 8, batch_first=True)\n",
            "    (h_proj_1_to_2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (c_proj_1_to_2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (h_proj_2_to_3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (c_proj_2_to_3): Linear(in_features=16, out_features=8, bias=True)\n",
            "  )\n",
            "  (fc1): Linear(in_features=8, out_features=16, bias=True)\n",
            "  (fc2): Linear(in_features=16, out_features=8, bias=True)\n",
            "  (decoder): decoder(\n",
            "    (lstm1): LSTM(8, 16, batch_first=True)\n",
            "    (lstm2): LSTM(16, 32, batch_first=True)\n",
            "    (lstm3): LSTM(32, 1382, batch_first=True)\n",
            "    (h_proj_1_to_2): Linear(in_features=16, out_features=32, bias=True)\n",
            "    (c_proj_1_to_2): Linear(in_features=16, out_features=32, bias=True)\n",
            "    (h_proj_2_to_3): Linear(in_features=32, out_features=1382, bias=True)\n",
            "    (c_proj_2_to_3): Linear(in_features=32, out_features=1382, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tt9nQfh2Qu09"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "def train():\n",
        "    model.train()\n",
        "    for d in train_loader:\n",
        "        #print(type(d))\n",
        "        x = d[0][0].to(device)\n",
        "        y = d[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x)\n",
        "        # print(out[0][9])\n",
        "        loss = criterion(out[0][train_window-1], y[0][0])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return float(loss)\n",
        "\n",
        "for epoch in range(6):\n",
        "    loss = train()\n",
        "    print(f'Epoch: {epoch+1:02d}, Loss: {loss:.4f}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "############ results\n",
        "########### result change layer 8 to 32\n",
        "# Epoch: 01, Loss: 0.0188\n",
        "# Epoch: 02, Loss: 0.0273\n",
        "# Epoch: 03, Loss: 0.0033\n",
        "# CPU times: user 6min 3s, sys: 3.62 s, total: 6min 6s\n",
        "# Wall time: 6min 12s\n",
        "\n",
        "########### result add hidden ayer 32\n",
        "# Epoch: 01, Loss: 0.0021\n",
        "# Epoch: 02, Loss: 0.0378\n",
        "# Epoch: 03, Loss: 0.0069\n",
        "# CPU times: user 7min 58s, sys: 4.28 s, total: 8min 2s\n",
        "# Wall time: 8min 11s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model with gpu\n",
        "# Epoch: 01, Loss: 0.0200\n",
        "# Epoch: 02, Loss: 0.0210\n",
        "# Epoch: 03, Loss: 0.0231\n",
        "# CPU times: user 13min 7s, sys: 14.9 s, total: 13min 22s\n",
        "# Wall time: 13min 5s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu\n",
        "# Epoch: 01, Loss: 0.0089\n",
        "# Epoch: 02, Loss: 0.0483\n",
        "# Epoch: 03, Loss: 0.0035\n",
        "# CPU times: user 12min 38s, sys: 13.5 s, total: 12min 51s\n",
        "# Wall time: 12min 34s\n",
        "\n",
        "########### result first ruad model with gpu and add timestamp column and window 10 and seq\n",
        "# Epoch: 01, Loss: 0.0107\n",
        "# Epoch: 02, Loss: 0.0098\n",
        "# Epoch: 03, Loss: 0.0219\n",
        "# CPU times: user 11min 17s, sys: 4.6 s, total: 11min 22s\n",
        "# Wall time: 11min 28s\n",
        "\n",
        "########### result first ruad model with gpu and add timestamp column and window 10 and remove seq\n",
        "# Epoch: 01, Loss: 0.0252\n",
        "# Epoch: 02, Loss: 0.0093\n",
        "# Epoch: 03, Loss: 0.0188\n",
        "# CPU times: user 11min 8s, sys: 4.67 s, total: 11min 12s\n",
        "# Wall time: 11min 19s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 10 and remove seq , adam optimizer\n",
        "# Epoch: 01, Loss: 0.0365\n",
        "# Epoch: 02, Loss: 0.0473\n",
        "# Epoch: 03, Loss: 0.0536\n",
        "# CPU times: user 12min 14s, sys: 13.8 s, total: 12min 28s\n",
        "# Wall time: 12min 12s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 10 and remove seq , SGD optimizer\n",
        "# Epoch: 01, Loss: 0.0594\n",
        "# Epoch: 02, Loss: 0.0260\n",
        "# Epoch: 03, Loss: 0.0311\n",
        "# CPU times: user 11min 27s, sys: 13.3 s, total: 11min 40s\n",
        "# Wall time: 11min 24s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 10 and remove seq , SGD optimizer, epoch 8\n",
        "# Epoch: 01, Loss: 0.0270\n",
        "# Epoch: 02, Loss: 0.0267\n",
        "# Epoch: 03, Loss: 0.0317\n",
        "# Epoch: 04, Loss: 0.0313\n",
        "# Epoch: 05, Loss: 0.0615\n",
        "# CPU times: user 19min 21s, sys: 23.7 s, total: 19min 44s\n",
        "# Wall time: 19min 18s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 10 and remove seq , SGD optimizer, epoch 5 , add h,c\n",
        "# Epoch: 01, Loss: 0.0211\n",
        "# Epoch: 02, Loss: 0.0153\n",
        "# Epoch: 03, Loss: 0.0244\n",
        "# Epoch: 04, Loss: 0.0031\n",
        "# Epoch: 05, Loss: 0.0129\n",
        "# CPU times: user 20min 12s, sys: 12 s, total: 20min 24s\n",
        "# Wall time: 20min 39s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 10 and remove seq , SGD optimizer, epoch 6 , add h,c\n",
        "# Epoch: 01, Loss: 0.0211\n",
        "# Epoch: 02, Loss: 0.0153\n",
        "# Epoch: 03, Loss: 0.0244\n",
        "# Epoch: 04, Loss: 0.0031\n",
        "# Epoch: 05, Loss: 0.0129\n",
        "# Epoch: 06, Loss: 0.0030\n",
        "# CPU times: user 24min 16s, sys: 14.37 s, total: 24min 30s\n",
        "# Wall time: 24min 48s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 20 and remove seq , SGD optimizer, epoch 6 , add h,c\n",
        "# Epoch: 01, Loss: 0.0042\n",
        "# Epoch: 02, Loss: 0.0035\n",
        "# Epoch: 03, Loss: 0.0061\n",
        "# Epoch: 04, Loss: 0.0053\n",
        "# Epoch: 05, Loss: 0.0214\n",
        "# Epoch: 06, Loss: 0.0109\n",
        "# CPU times: user 26min 13s, sys: 14.2 s, total: 26min 27s\n",
        "# Wall time: 26min 46s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 20 and remove seq , SGD optimizer, epoch 6 , add h,c ,len(data)=1351\n",
        "# Epoch: 01, Loss: 0.0111\n",
        "# Epoch: 02, Loss: 0.2479\n",
        "# Epoch: 03, Loss: 0.0097\n",
        "# Epoch: 04, Loss: 0.0052\n",
        "# Epoch: 05, Loss: 0.0080\n",
        "# Epoch: 06, Loss: 0.0088\n",
        "# CPU times: user 41min 57s, sys: 15.8 s, total: 42min 12s\n",
        "# Wall time: 42min 38s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 10 and remove seq , SGD optimizer, epoch 6 , add h,c ,len(data)=1351\n",
        "# Epoch: 01, Loss: 0.0080\n",
        "# Epoch: 02, Loss: 0.0062\n",
        "# Epoch: 03, Loss: 0.0100\n",
        "# Epoch: 04, Loss: 0.2012\n",
        "# Epoch: 05, Loss: 0.0097\n",
        "# Epoch: 06, Loss: 0.0084\n",
        "# CPU times: user 47min 20s, sys: 21.4 s, total: 47min 41s\n",
        "# Wall time: 48min 17s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 10 and remove seq , SGD optimizer, epoch 6  ,len(data)=1351\n",
        "# Epoch: 01, Loss: 0.0100\n",
        "# Epoch: 02, Loss: 0.0079\n",
        "# Epoch: 03, Loss: 0.0118\n",
        "# Epoch: 04, Loss: 0.0127\n",
        "# Epoch: 05, Loss: 0.2008\n",
        "# Epoch: 06, Loss: 0.1996\n",
        "# CPU times: user 1h 1min 51s, sys: 48.3 s, total: 1h 2min 40s\n",
        "# Wall time: 1h 1min 51s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 20 and remove seq , SGD optimizer, epoch 6 , add h,c ,len(data)=1350 (remove time)\n",
        "# Epoch: 01, Loss: 0.0132\n",
        "# Epoch: 02, Loss: 0.0073\n",
        "# Epoch: 03, Loss: 0.0063\n",
        "# Epoch: 04, Loss: 0.0073\n",
        "# Epoch: 05, Loss: 0.0050\n",
        "# Epoch: 06, Loss: 0.0042\n",
        "# CPU times: user 40min 43s, sys: 12.6 s, total: 40min 56s\n",
        "# Wall time: 41min 23s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 20 and remove seq , SGD optimizer, epoch 6 , add h,c ,len(data)=1382 (with time)\n",
        "# Epoch: 01, Loss: 0.0123\n",
        "# Epoch: 02, Loss: 0.0086\n",
        "# Epoch: 03, Loss: 0.0139\n",
        "# Epoch: 04, Loss: 0.0281\n",
        "# Epoch: 05, Loss: 0.0211\n",
        "# Epoch: 06, Loss: 0.0112\n",
        "# CPU times: user 41min 51s, sys: 11.9 s, total: 42min 3s\n",
        "# Wall time: 42min 32s\n",
        "\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 20 and remove seq , SGD optimizer, epoch 6 , add h,c ,len(data)=1382 (with time) change in next_value\n",
        "# Epoch: 01, Loss: 0.0104\n",
        "# Epoch: 02, Loss: 0.0312\n",
        "# Epoch: 03, Loss: 0.0147\n",
        "# Epoch: 04, Loss: 0.0170\n",
        "# Epoch: 05, Loss: 0.0135\n",
        "# Epoch: 06, Loss: 0.0116\n",
        "# CPU times: user 41min 27s, sys: 10.2 s, total: 41min 37s\n",
        "# Wall time: 42min 5s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 20 and remove seq , SGD optimizer, epoch 6 , add h,c ,len(data)=1382 (with time) change in next_value , lr=0.03 in data\n",
        "# Epoch: 01, Loss: 0.0389\n",
        "# Epoch: 02, Loss: 0.0300\n",
        "# Epoch: 03, Loss: 0.0065\n",
        "# Epoch: 04, Loss: 0.0226\n",
        "# Epoch: 05, Loss: 0.0122\n",
        "# Epoch: 06, Loss: 0.0110\n",
        "# CPU times: user 42min 44s, sys: 13.1 s, total: 42min 57s\n",
        "# Wall time: 41min 44s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 20 and remove seq , SGD optimizer, epoch 6 , add h,c ,len(data)=1382 (with time) change in next_value , lr=0.03 in data and lr 0.05 in detection\n",
        "# Epoch: 01, Loss: 0.0129\n",
        "# Epoch: 02, Loss: 0.0109\n",
        "# Epoch: 03, Loss: 0.0065\n",
        "# Epoch: 04, Loss: 0.0189\n",
        "# Epoch: 05, Loss: 0.0124\n",
        "# Epoch: 06, Loss: 0.0080\n",
        "# CPU times: user 43min 24s, sys: 13.1 s, total: 42min 57s\n",
        "# Wall time: 41min 34s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 20 and remove seq , SGD optimizer, epoch 6 , add h,c ,len(data)=1382 (with time) change in next_value , lr=0.03 in data and lr 0.07 in detection\n",
        "# Epoch: 01, Loss: 0.0117\n",
        "# Epoch: 02, Loss: 0.0056\n",
        "# Epoch: 03, Loss: 0.0075\n",
        "# Epoch: 04, Loss: 0.0077\n",
        "# Epoch: 05, Loss: 0.0088\n",
        "# Epoch: 06, Loss: 0.0110\n",
        "# CPU times: user 42min 49s, sys: 12.9 s, total: 43min 2s\n",
        "# Wall time: 43min 44s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 20 and remove seq , SGD optimizer, epoch 6 , add h,c ,len(data)=1382 (with time) change in next_value , lr=0.03 in data and lr 0.09 in detection\n",
        "# Epoch: 01, Loss: 0.0097\n",
        "# Epoch: 02, Loss: 0.0093\n",
        "# Epoch: 03, Loss: 0.0081\n",
        "# Epoch: 04, Loss: 0.0130\n",
        "# Epoch: 05, Loss: 0.0092\n",
        "# Epoch: 06, Loss: 0.0059\n",
        "# CPU times: user 42min 23s, sys: 13 s, total: 42min 36s\n",
        "# Wall time: 43min 6s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 20 and remove seq , SGD optimizer, epoch 6 , add h,c ,len(data)=1382 (with time) change in next_value , lr=0.03 in data and lr 0.3 in detection\n",
        "# Epoch: 01, Loss: 0.0065\n",
        "# Epoch: 02, Loss: 0.0101\n",
        "# Epoch: 03, Loss: 0.0100\n",
        "# Epoch: 04, Loss: 0.0058\n",
        "# Epoch: 05, Loss: 0.0058\n",
        "# Epoch: 06, Loss: 0.0031\n",
        "# CPU times: user 42min 32s, sys: 12.4 s, total: 42min 44s\n",
        "# Wall time: 43min 13s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogU-wULvQu09"
      },
      "outputs": [],
      "source": [
        "def test(x):\n",
        "    model.eval()\n",
        "    x = x.to(device)\n",
        "    out = model(x)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHNcfzkSQu0-"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error,roc_auc_score\n",
        "reconstruction = []\n",
        "loss = []\n",
        "#y_true = []\n",
        "for d in test_loader:\n",
        "    x = d[0][0]\n",
        "    y = d[1]\n",
        "    out = test(x)\n",
        "    reconstruction.append(out)\n",
        "    loss.append(mean_squared_error(out[0][train_window-1].detach().cpu().numpy(),y[0][0]))\n",
        "    #y_true.append(d[1].detach().cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LYPX4CKQu0-"
      },
      "outputs": [],
      "source": [
        "# test_seq_label = create_data_seq(test_labels,train_window,revelent_len)\n",
        "test_seq_label = create_data_seq(test_labels,train_window)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJaVsXaAQu0_"
      },
      "outputs": [],
      "source": [
        "temp_list = []\n",
        "for i in range(len(test_seq_label)):\n",
        "    temp = test_seq_label[i][1].type(torch.int64)\n",
        "    temp = temp.detach().cpu().numpy().tolist()\n",
        "    temp_list.append(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-WZzWbjQu0_"
      },
      "outputs": [],
      "source": [
        "y_true = []\n",
        "for i in range(len(temp_list)):\n",
        "    y_true.append(temp_list[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHHG9P2BQu0_"
      },
      "outputs": [],
      "source": [
        "error_df = pd.DataFrame({'loss': loss,\n",
        "                        'true_class': y_true})\n",
        "error_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9ilQ6bBQu0_"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(error_df['true_class'],error_df['loss'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#0.8765328998395648\n",
        "#0.8723729179726375    result of change hidden layer from 8 to 32\n",
        "#0.9065247187071686    result of add one layer 32 between encoder :)\n",
        "#0.904416749009233     result add hidden layer 32 to decoder too and add decoder to ruad model with gpu (this is pretty good)\n",
        "#0.8655186444515994    result first ruad model with gpu and add timestamp column and woindow 10 and seq , adam optimizer\n",
        "#0.8967381497429511    result first ruad model with gpu and add timestamp column and woindow 10 and remove seq , adam optimizer\n",
        "#0.3060959342747257    result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 10 and remove seq, adam optimizer\n",
        "#0.34766214604908874   result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 10 and remove seq, SGD optimizer\n",
        "#0.36209899126422795   result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 10 and remove seq, SGD optimizer , epoch 5 +3 (i forgot to reset)\n",
        "#0.907213292243243     result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 10 and remove seq, SGD optimizer , epoch 5 , add , h,c\n",
        "#0.9098181020482538    result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 10 and remove seq, SGD optimizer , epoch 6 , add , h,c\n",
        "#0.9069957536027086    result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 20 and remove seq, SGD optimizer , epoch 6 , add , h,c --- moshtrak\n",
        "#0.9345063164717007    result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 20 and remove seq , SGD optimizer, epoch 6 , add h,c ,len(data)=1351, with time\n",
        "#0.6694775694129658    result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 10 and remove seq , SGD optimizer, epoch 6 , add h,c ,len(data)=1351 , with time\n",
        "#0.6529441138631129    result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 10 and remove seq, SGD optimizer , epoch 6 ,len(data)=1350, with time\n",
        "#0.9342669032465992    result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 20 and remove seq , SGD optimizer, epoch 6 , add h,c ,len(data)=1350, (remove time)\n",
        "#0.28216920571045323    result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 20 and remove seq , SGD optimizer, epoch 6 , add h,c ,len(data)=1382, (with time) , lr =0.03\n",
        "#0.7664079716393599    result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 20 and remove seq , SGD optimizer, epoch 6 , add h,c ,len(data)=1382, (with time) , lr =0.03 for model to detect lr=0.05\n",
        "#0.7617131359586088    result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 20 and remove seq , SGD optimizer, epoch 6 , add h,c ,len(data)=1382, (with time) , lr =0.03 for model to detect lr=0.07\n",
        "#0.7964932451853981    result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 20 and remove seq , SGD optimizer, epoch 6 , add h,c ,len(data)=1382, (with time) , lr =0.03 for model to detect lr=0.09\n",
        "#0.8641372041774456    result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 20 and remove seq , SGD optimizer, epoch 6 , add h,c ,len(data)=1382, (with time) , lr =0.03 for model to detect lr=0.3"
      ],
      "metadata": {
        "id": "0H5GYfJ0T5xq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}