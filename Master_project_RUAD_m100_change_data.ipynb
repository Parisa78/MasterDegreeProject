{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXJOdzIXQu0z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.transforms import ToTensor\n",
        "from pandas import Series\n",
        "import numpy as np\n",
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofAfliT7WRP4"
      },
      "outputs": [],
      "source": [
        "#The dataset, collected on the Marconi 100 system, has been published and\n",
        "#described in the Scientific dataset publication: https://www.nature.com/articles/s41597-023-02174-3\n",
        "#It is available on Zenodo: https://zenodo.org/records/7541722\n",
        "\n",
        "\n",
        "#This is rack 1 of the dataset\n",
        "!wget https://zenodo.org/record/7541722/files/1.tar?download=1 -o rack.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4NUMrbtXOIt"
      },
      "outputs": [],
      "source": [
        "!tar -xf /content/1.tar?download=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XGtDIafQu00"
      },
      "outputs": [],
      "source": [
        "#This is node 36, of rack 1\n",
        "file_name = '36.parquet'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "ZDXmjiSqQu01",
        "outputId": "f12ced9a-4719-42b3-e05d-5d2bd1e97998"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  timestamp  ambient_avg  ambient_std  ambient_min  \\\n",
              "0 2020-03-09 12:00:00+00:00    21.636362     0.077138    21.600000   \n",
              "1 2020-03-09 12:15:00+00:00    21.860000     0.128063    21.600000   \n",
              "2 2020-03-09 12:30:00+00:00    21.885714     0.098975    21.799999   \n",
              "3 2020-03-09 12:45:00+00:00    21.918917     0.098194    21.799999   \n",
              "4 2020-03-09 13:00:00+00:00    21.875553     0.096967    21.799999   \n",
              "\n",
              "   ambient_max  dimm0_temp_avg  dimm0_temp_std  dimm0_temp_min  \\\n",
              "0    21.799999            29.0             0.0            29.0   \n",
              "1    22.000000            29.0             0.0            29.0   \n",
              "2    22.000000            29.0             0.0            29.0   \n",
              "3    22.000000            29.0             0.0            29.0   \n",
              "4    22.000000            29.0             0.0            29.0   \n",
              "\n",
              "   dimm0_temp_max  dimm10_temp_avg  ...  ps1_output_curre_max  \\\n",
              "0            29.0             30.0  ...                  22.0   \n",
              "1            29.0             30.0  ...                  21.0   \n",
              "2            29.0             30.0  ...                  21.0   \n",
              "3            29.0             30.0  ...                  20.0   \n",
              "4            29.0             30.0  ...                  21.0   \n",
              "\n",
              "   ps1_output_volta_avg  ps1_output_volta_std  ps1_output_volta_min  \\\n",
              "0             12.399999                   0.0                  12.4   \n",
              "1             12.399998                   0.0                  12.4   \n",
              "2             12.399999                   0.0                  12.4   \n",
              "3             12.399999                   0.0                  12.4   \n",
              "4             12.400001                   0.0                  12.4   \n",
              "\n",
              "   ps1_output_volta_max  total_power_avg  total_power_std  total_power_min  \\\n",
              "0                  12.4            400.0              0.0            400.0   \n",
              "1                  12.4            400.0              0.0            400.0   \n",
              "2                  12.4            400.0              0.0            400.0   \n",
              "3                  12.4            400.0              0.0            400.0   \n",
              "4                  12.4            400.0              0.0            400.0   \n",
              "\n",
              "   total_power_max  value  \n",
              "0            400.0   <NA>  \n",
              "1            400.0   <NA>  \n",
              "2            400.0   <NA>  \n",
              "3            400.0   <NA>  \n",
              "4            400.0   <NA>  \n",
              "\n",
              "[5 rows x 354 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-368b3273-1ef9-44fc-a15b-819a61eead76\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>ambient_avg</th>\n",
              "      <th>ambient_std</th>\n",
              "      <th>ambient_min</th>\n",
              "      <th>ambient_max</th>\n",
              "      <th>dimm0_temp_avg</th>\n",
              "      <th>dimm0_temp_std</th>\n",
              "      <th>dimm0_temp_min</th>\n",
              "      <th>dimm0_temp_max</th>\n",
              "      <th>dimm10_temp_avg</th>\n",
              "      <th>...</th>\n",
              "      <th>ps1_output_curre_max</th>\n",
              "      <th>ps1_output_volta_avg</th>\n",
              "      <th>ps1_output_volta_std</th>\n",
              "      <th>ps1_output_volta_min</th>\n",
              "      <th>ps1_output_volta_max</th>\n",
              "      <th>total_power_avg</th>\n",
              "      <th>total_power_std</th>\n",
              "      <th>total_power_min</th>\n",
              "      <th>total_power_max</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-03-09 12:00:00+00:00</td>\n",
              "      <td>21.636362</td>\n",
              "      <td>0.077138</td>\n",
              "      <td>21.600000</td>\n",
              "      <td>21.799999</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>...</td>\n",
              "      <td>22.0</td>\n",
              "      <td>12.399999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.4</td>\n",
              "      <td>12.4</td>\n",
              "      <td>400.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-03-09 12:15:00+00:00</td>\n",
              "      <td>21.860000</td>\n",
              "      <td>0.128063</td>\n",
              "      <td>21.600000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>...</td>\n",
              "      <td>21.0</td>\n",
              "      <td>12.399998</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.4</td>\n",
              "      <td>12.4</td>\n",
              "      <td>400.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-03-09 12:30:00+00:00</td>\n",
              "      <td>21.885714</td>\n",
              "      <td>0.098975</td>\n",
              "      <td>21.799999</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>...</td>\n",
              "      <td>21.0</td>\n",
              "      <td>12.399999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.4</td>\n",
              "      <td>12.4</td>\n",
              "      <td>400.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-03-09 12:45:00+00:00</td>\n",
              "      <td>21.918917</td>\n",
              "      <td>0.098194</td>\n",
              "      <td>21.799999</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>...</td>\n",
              "      <td>20.0</td>\n",
              "      <td>12.399999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.4</td>\n",
              "      <td>12.4</td>\n",
              "      <td>400.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-03-09 13:00:00+00:00</td>\n",
              "      <td>21.875553</td>\n",
              "      <td>0.096967</td>\n",
              "      <td>21.799999</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>...</td>\n",
              "      <td>21.0</td>\n",
              "      <td>12.400001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.4</td>\n",
              "      <td>12.4</td>\n",
              "      <td>400.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 354 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-368b3273-1ef9-44fc-a15b-819a61eead76')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-368b3273-1ef9-44fc-a15b-819a61eead76 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-368b3273-1ef9-44fc-a15b-819a61eead76');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c4888f3a-4d17-457d-9618-ab72b6ff38eb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c4888f3a-4d17-457d-9618-ab72b6ff38eb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c4888f3a-4d17-457d-9618-ab72b6ff38eb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "DATA"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "DATA = pd.read_parquet(file_name)\n",
        "DATA.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiFEl64MUX7u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45ef6a93-5b0e-453d-bc80-c14ae992c046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-07ca0595a954>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  DATA['value'] = DATA['value'].replace(2,1)\n",
            "<ipython-input-7-07ca0595a954>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  DATA['value'] = DATA['value'].replace(3,1)\n"
          ]
        }
      ],
      "source": [
        "#The dataset has periods of unavailability of Nagios traces, as described in the dataset paper:  https://www.nature.com/articles/s41597-023-02174-3/figures/3\n",
        "#We suggest dropping the periods where the labels are largely unavailable and using the dataset either after 1.4.2021 or 1.10.2021.\n",
        "DATA = DATA[DATA['timestamp'] > '2021-04-01']\n",
        "\n",
        "### parisa change\n",
        "DATA['value'] = DATA['value'].replace(2,1)\n",
        "DATA['value'] = DATA['value'].replace(3,1)\n",
        "## parisa change"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQkJAI-cNPUG"
      },
      "outputs": [],
      "source": [
        "DATA.reset_index(drop=True, inplace = True)\n",
        "DATA = DATA.fillna(0)\n",
        "DATA['timestamp'] = pd.to_datetime(DATA['timestamp'])\n",
        "l = DATA.timestamp.diff() == pd.Timedelta(minutes=15) #time consistency -> measurements should be 15 minutes apart\n",
        "chunks = []\n",
        "current_chunk = []\n",
        "for index, value in enumerate(l):\n",
        "    current_chunk.append(DATA.iloc[index])\n",
        "    if not value:\n",
        "        chunks.append(pd.DataFrame(current_chunk))\n",
        "        current_chunk = []\n",
        "\n",
        "\n",
        "if current_chunk:\n",
        "    chunks.append(pd.DataFrame(current_chunk))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "revelent_len = [len(c) for c in chunks] ### pak she"
      ],
      "metadata": {
        "id": "vM0nOixV_pqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA['value'] = DATA['value'].replace(2,1)\n",
        "DATA['value'] = DATA['value'].replace(3,1)\n",
        "\n",
        "### parisa change\n",
        "relevant = [c for c in chunks if len(c) >= 20] #assuming time window of 20\n",
        "revelent_len = [len(c) for c in chunks if len(c) >= 20]\n",
        "DATA2 = pd.concat(relevant)\n",
        "DATA = DATA2\n",
        "DATA['value'] = DATA['value'].replace(2,1)\n",
        "DATA['value'] = DATA['value'].replace(3,1)\n",
        "\n",
        "### parisa change end\n",
        "##3 parisa change\n",
        "# relevant = [c for c in chunks if len(c) >= 20] #assuming time window of 20\n",
        "# DATA2 = pd.concat(relevant)\n",
        "# DATA = DATA2\n",
        "# DATA['value'] = DATA['value'].replace(2,1)\n",
        "# DATA['value'] = DATA['value'].replace(3,1)\n",
        "# DATA = DATA.drop(columns=['timestamp'])\n",
        "# DATA = DATA.astype(float)\n",
        "##3 parisa change end"
      ],
      "metadata": {
        "id": "MWVL8xDF579k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA3= DATA\n",
        "DATA=DATA.drop(columns=['timestamp'])\n",
        "DATA = DATA.astype(float)"
      ],
      "metadata": {
        "id": "fpEk6-otzJku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2IMXqzoQu03"
      },
      "outputs": [],
      "source": [
        "scaler = preprocessing.MinMaxScaler()\n",
        "names = DATA.columns\n",
        "d = scaler.fit_transform(DATA)\n",
        "DATA = pd.DataFrame(d, columns=names)\n",
        "### parisa change\n",
        "# DATA['timestamp'] = DATA3['timestamp'].astype('int64') // 10**9\n",
        "timestamp_scaler = preprocessing.MinMaxScaler()\n",
        "DATA['timestamp'] = timestamp_scaler.fit_transform(DATA3['timestamp'].astype('int64').values.reshape(-1, 1))\n",
        "#### parisa change end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJlNWM1tQu03"
      },
      "outputs": [],
      "source": [
        "train_data = DATA[:int(DATA.shape[0]*0.8)]\n",
        "test_data = DATA[int(DATA.shape[0]*0.8):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiA7OH9WQu03",
        "outputId": "a8b35c13-2b69-47c7-9558-b088704cb28b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((41847, 354), (10462, 354))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "train_data.shape,test_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWVtf7vpQu03",
        "outputId": "a2b39fb3-c39a-4f85-c843-85efc7d8d582"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41847, 354)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "train_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "VUT7QzOKQu04",
        "outputId": "bb334d9f-840f-403e-82ba-1709277539c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "value\n",
              "0.0    40673\n",
              "1.0     1174\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>value</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>40673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>1174</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "train_data['value'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onXqoqEGQu04"
      },
      "outputs": [],
      "source": [
        "train_feat = train_data.drop(columns=['value'])\n",
        "train_feat = train_feat.to_numpy()\n",
        "test_feat = test_data.drop(columns=['value'])\n",
        "test_feat = test_feat.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TKEoNSjQu04"
      },
      "outputs": [],
      "source": [
        "train_feat = torch.tensor(train_feat, dtype=torch.float)\n",
        "test_feat = torch.tensor(test_feat, dtype=torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Of6oEPbQu05",
        "outputId": "d61263ff-2440-40ef-8f95-15bbe82c109e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0.,  ..., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "test_labels = test_data['value']\n",
        "test_labels = test_labels.to_numpy()\n",
        "test_labels = torch.tensor(test_labels, dtype=torch.float)\n",
        "test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlsEjPJ0Qu05"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z95V8uGGQu05"
      },
      "outputs": [],
      "source": [
        "train_window = 20 ## 20\n",
        "\n",
        "def create_data_seq(data,tw):\n",
        "    seq = []\n",
        "    for i in range(len(data)-tw):\n",
        "        x_seq = data[i:i+tw],\n",
        "        y_seq = data[i+tw:i+tw+1]  ###در ترین میاد 0 تا 20 رو میده و میگه 21 رو حدس بزن\n",
        "        seq.append((x_seq,y_seq))\n",
        "    return seq\n",
        "### parisa change\n",
        "# def create_data_seq(data, tw, relevant_len):\n",
        "#     seq = []\n",
        "#     start_idx = 0\n",
        "\n",
        "#     for length in relevant_len:\n",
        "#         end_idx = start_idx + length\n",
        "\n",
        "#         for i in range(start_idx, end_idx):\n",
        "#             # Determine the actual window size\n",
        "#             actual_tw = min(tw, length)\n",
        "\n",
        "#             if i + actual_tw >= end_idx:\n",
        "#                 break\n",
        "\n",
        "#             # Create x_seq and y_seq\n",
        "#             x_seq = data[i:i+actual_tw].unsqueeze(0)  # Add batch dimension here\n",
        "#             y_seq = data[i+actual_tw:i+actual_tw+1]\n",
        "\n",
        "#             if len(y_seq) > 0:\n",
        "#                 seq.append((x_seq, y_seq))\n",
        "\n",
        "#         start_idx = end_idx\n",
        "\n",
        "#     return seq\n",
        "\n",
        "## parisa change end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQND2EJuQu06"
      },
      "outputs": [],
      "source": [
        "# train_seq = create_data_seq(train_feat,train_window,revelent_len) ## parisa change\n",
        "train_seq = create_data_seq(train_feat,train_window) ## parisa change"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0].size()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBUaUQkBNNdg",
        "outputId": "392b6153-e166-432f-fb39-604fc7d46574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 20, 353])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xnsh7J1Qu06",
        "outputId": "cf605801-0006-4d07-82af-a01df545ffa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[[0.5593, 0.0174, 0.5896,  ..., 0.3919, 0.7917, 0.0394],\n",
            "         [0.5571, 0.0159, 0.5896,  ..., 0.3919, 0.8333, 0.0394],\n",
            "         [0.5579, 0.0220, 0.5849,  ..., 0.3919, 0.7708, 0.0395],\n",
            "         ...,\n",
            "         [0.5607, 0.0056, 0.5943,  ..., 0.3784, 0.8438, 0.0397],\n",
            "         [0.5571, 0.0196, 0.5849,  ..., 0.3649, 0.7500, 0.0398],\n",
            "         [0.5554, 0.0139, 0.5849,  ..., 0.3649, 0.7708, 0.0398]]])]\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_seq, batch_size=1, shuffle=True)\n",
        "\n",
        "X,y  = next(iter(train_loader))\n",
        "print(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = next(iter(train_loader))\n",
        "print(X)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkP0CqVFpEd7",
        "outputId": "84b561f7-a275-4e16-d782-012d8d6a3b5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[[0.4983, 0.0000, 0.5283,  ..., 0.3514, 0.4479, 0.4595],\n",
            "         [0.4982, 0.0056, 0.5236,  ..., 0.3378, 0.6667, 0.4595],\n",
            "         [0.4975, 0.0146, 0.5236,  ..., 0.3514, 0.8333, 0.4595],\n",
            "         ...,\n",
            "         [0.4983, 0.0000, 0.5283,  ..., 0.3514, 0.8125, 0.4596],\n",
            "         [0.4983, 0.0000, 0.5283,  ..., 0.3378, 0.8125, 0.4597],\n",
            "         [0.4978, 0.0120, 0.5236,  ..., 0.3514, 0.7812, 0.4597]]])]\n",
            "tensor([[[0.4983, 0.0000, 0.5283, 0.4628, 0.6643, 0.0713, 0.6889, 0.6531,\n",
            "          0.6485, 0.0000, 0.6739, 0.6200, 0.6308, 0.0000, 0.6522, 0.6000,\n",
            "          0.6393, 0.0000, 0.6596, 0.6078, 0.6452, 0.0000, 0.6809, 0.6154,\n",
            "          0.6279, 0.0000, 0.6522, 0.6000, 0.6555, 0.1578, 0.6667, 0.6346,\n",
            "          0.6766, 0.1540, 0.6889, 0.6400, 0.6678, 0.1450, 0.6889, 0.6400,\n",
            "          0.6766, 0.1529, 0.6889, 0.6400, 0.6574, 0.0000, 0.6889, 0.6200,\n",
            "          0.6605, 0.0000, 0.6889, 0.6200, 0.6555, 0.0000, 0.6739, 0.6200,\n",
            "          0.6545, 0.1720, 0.6667, 0.6327, 0.6347, 0.0000, 0.6522, 0.6000,\n",
            "          0.6443, 0.0000, 0.6596, 0.6078, 0.4683, 0.0080, 0.5658, 0.3826,\n",
            "          0.4943, 0.0000, 0.5875, 0.4312, 0.4731, 0.0000, 0.5733, 0.3981,\n",
            "          0.4934, 0.0000, 0.5875, 0.4352, 0.4681, 0.0054, 0.5658, 0.4037,\n",
            "          0.4930, 0.0038, 0.5750, 0.4352, 0.4696, 0.0113, 0.5658, 0.4037,\n",
            "          0.4937, 0.0000, 0.5875, 0.4352, 0.1731, 0.0175, 0.2941, 0.1385,\n",
            "          0.5880, 0.1999, 0.5513, 0.6914, 0.5775, 0.1939, 0.5429, 0.6623,\n",
            "          0.5748, 0.1214, 0.5488, 0.6429, 0.5753, 0.1251, 0.5467, 0.6329,\n",
            "          0.5381, 0.1582, 0.5522, 0.5974, 0.5101, 0.1630, 0.5231, 0.6164,\n",
            "          0.5492, 0.1446, 0.5250, 0.6386, 0.5883, 0.1732, 0.5634, 0.6800,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.8647, 0.3305, 0.7826, 0.9315, 0.8543, 0.2661, 0.7910, 0.9143,\n",
            "          0.6658, 0.0758, 0.6377, 0.6667, 0.6505, 0.0746, 0.6286, 0.6486,\n",
            "          0.6595, 0.0759, 0.6377, 0.6575, 0.6736, 0.0783, 0.6471, 0.6667,\n",
            "          0.6741, 0.0779, 0.6471, 0.6761, 0.6561, 0.0696, 0.6286, 0.6667,\n",
            "          0.6533, 0.0670, 0.6286, 0.6486, 0.6657, 0.0672, 0.6377, 0.6575,\n",
            "          0.6550, 0.0664, 0.6429, 0.6486, 0.6515, 0.0639, 0.6429, 0.6316,\n",
            "          0.6513, 0.0618, 0.6338, 0.6316, 0.6683, 0.0654, 0.6377, 0.6486,\n",
            "          0.8638, 0.3503, 0.7794, 0.9167, 0.8698, 0.3485, 0.7910, 0.9167,\n",
            "          0.8231, 0.2275, 0.8438, 0.7949, 0.4576, 0.2285, 0.4286, 0.6429,\n",
            "          0.3448, 0.1589, 0.1584, 0.3111, 0.7145, 0.0379, 0.7083, 0.6923,\n",
            "          0.5546, 0.0522, 0.5538, 0.5507, 0.5656, 0.0572, 0.5714, 0.5758,\n",
            "          0.5790, 0.0502, 0.5902, 0.5846, 0.5409, 0.0430, 0.5455, 0.5429,\n",
            "          0.5360, 0.0633, 0.5303, 0.5571, 0.5554, 0.0457, 0.5469, 0.5522,\n",
            "          0.5508, 0.0420, 0.5625, 0.5429, 0.5717, 0.0432, 0.5714, 0.5606,\n",
            "          0.5661, 0.0395, 0.5625, 0.5441, 0.5550, 0.0457, 0.5455, 0.5588,\n",
            "          0.5395, 0.0694, 0.5373, 0.6087, 0.5203, 0.0371, 0.5143, 0.5278,\n",
            "          0.5171, 0.0439, 0.5143, 0.5417, 0.5398, 0.0494, 0.5373, 0.5652,\n",
            "          0.5577, 0.0526, 0.5538, 0.5821, 0.5597, 0.0471, 0.5538, 0.5652,\n",
            "          0.7958, 0.1366, 0.8361, 0.7368, 0.3959, 0.0261, 0.4500, 0.3704,\n",
            "          0.1235, 0.0168, 0.1212, 0.1119, 0.6119, 0.0106, 0.6250, 0.5962,\n",
            "          0.7614, 0.0516, 0.7627, 0.7486, 0.4004, 0.2109, 0.3580, 0.5978,\n",
            "          0.9667, 0.0000, 0.9741, 0.9658, 0.3610, 0.0999, 0.3390, 0.4231,\n",
            "          0.9839, 0.0000, 0.9839, 0.9839, 0.4243, 0.1913, 0.3929, 0.6082,\n",
            "          0.9719, 0.0236, 0.9658, 0.9661, 0.3910, 0.2681, 0.3548, 0.8101,\n",
            "          0.9839, 0.0000, 0.9839, 0.9839, 0.3643, 0.2727, 0.3514, 0.8229,\n",
            "          0.4597]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dC4Ja5rSQu06"
      },
      "outputs": [],
      "source": [
        "# test_seq = create_data_seq(test_feat,train_window,revelent_len)\n",
        "test_seq = create_data_seq(test_feat,train_window)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxlFxsRtQu06"
      },
      "outputs": [],
      "source": [
        "test_loader = DataLoader(test_seq, batch_size=1, shuffle=False) ## در هر فور ما یه تعدادی بچ داریم که میدیم به دل با بچ بیشتر میتونیم بگیم مثلا 2 تا 2 تا بهش بده\n",
        "X,y = next(iter(test_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDfQgT_hQu07"
      },
      "outputs": [],
      "source": [
        "class encoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.lstm1 = torch.nn.LSTM(\n",
        "            input_size=353,\n",
        "            hidden_size=16,\n",
        "            batch_first=True,\n",
        "            num_layers=1\n",
        "        )\n",
        "        self.lstm2 = torch.nn.LSTM(\n",
        "          input_size=16,\n",
        "          hidden_size=8,\n",
        "          num_layers=1,\n",
        "          batch_first=True\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        h0 = torch.zeros(1, batch_size, 16).requires_grad_().to(device)\n",
        "        c0 = torch.zeros(1, batch_size, 16).requires_grad_().to(device)\n",
        "\n",
        "        x, (_, _) = self.lstm1(x, (h0, c0))\n",
        "\n",
        "        h0 = torch.zeros(1, batch_size,8).requires_grad_().to(device)\n",
        "        c0 = torch.zeros(1, batch_size, 8).requires_grad_().to(device)\n",
        "        x, (_, _) = self.lstm2(x, (h0, c0))\n",
        "        return x[:, :, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWDhY2QLvvRO"
      },
      "outputs": [],
      "source": [
        "############### mine\n",
        "# class encoder(torch.nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "\n",
        "#         self.lstm1 = torch.nn.LSTM(\n",
        "#             input_size=352,\n",
        "#             hidden_size=32,\n",
        "#             batch_first=True,\n",
        "#             num_layers=1\n",
        "#         )\n",
        "#         self.lstm2 = torch.nn.LSTM(\n",
        "#           input_size=32,\n",
        "#           hidden_size=8,\n",
        "#           num_layers=1,\n",
        "#           batch_first=True\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         batch_size = x.shape[0]\n",
        "#         h0 = torch.zeros(1, batch_size, 32).requires_grad_().to(device)\n",
        "#         c0 = torch.zeros(1, batch_size, 32).requires_grad_().to(device)\n",
        "\n",
        "#         x, (_, _) = self.lstm1(x, (h0, c0))\n",
        "\n",
        "#         h0 = torch.zeros(1, batch_size,8).requires_grad_().to(device)\n",
        "#         c0 = torch.zeros(1, batch_size, 8).requires_grad_().to(device)\n",
        "#         x, (_, _) = self.lstm2(x, (h0, c0))\n",
        "#         return x[:, :, :]\n",
        "\n",
        "class encoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # First LSTM layer\n",
        "        self.lstm1 = torch.nn.LSTM(\n",
        "            input_size=353,\n",
        "            hidden_size=32,  # Increased the hidden size for this example\n",
        "            batch_first=True,\n",
        "            num_layers=1\n",
        "        )\n",
        "\n",
        "        # Second LSTM layer\n",
        "        self.lstm2 = torch.nn.LSTM(\n",
        "            input_size=32,   # Input size matches the hidden size of lstm1\n",
        "            hidden_size=16,\n",
        "            batch_first=True,\n",
        "            num_layers=1\n",
        "        )\n",
        "\n",
        "        # Third LSTM layer (newly added)\n",
        "        self.lstm3 = torch.nn.LSTM(\n",
        "            input_size=16,   # Input size matches the hidden size of lstm2\n",
        "            hidden_size=8,\n",
        "            batch_first=True,\n",
        "            num_layers=1\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        # Initial hidden and cell states for lstm1\n",
        "        h0 = torch.zeros(1, batch_size, 32).requires_grad_().to(device)\n",
        "        c0 = torch.zeros(1, batch_size, 32).requires_grad_().to(device)\n",
        "        x, (_, _) = self.lstm1(x, (h0, c0))\n",
        "\n",
        "        # Initial hidden and cell states for lstm2\n",
        "        h0 = torch.zeros(1, batch_size, 16).requires_grad_().to(device)\n",
        "        c0 = torch.zeros(1, batch_size, 16).requires_grad_().to(device)\n",
        "        x, (_, _) = self.lstm2(x, (h0, c0))\n",
        "\n",
        "        # Initial hidden and cell states for lstm3\n",
        "        h0 = torch.zeros(1, batch_size, 8).requires_grad_().to(device)\n",
        "        c0 = torch.zeros(1, batch_size, 8).requires_grad_().to(device)\n",
        "        x, (_, _) = self.lstm3(x, (h0, c0))\n",
        "\n",
        "        return x[:, :, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TF38j7s0Qu07"
      },
      "outputs": [],
      "source": [
        "class decoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.lstm1 = torch.nn.LSTM(\n",
        "            input_size=8,\n",
        "            hidden_size=16,\n",
        "            batch_first=True,\n",
        "            num_layers=1\n",
        "        )\n",
        "        self.lstm2 = torch.nn.LSTM(\n",
        "          input_size=16,\n",
        "          hidden_size=353,\n",
        "          num_layers=1,\n",
        "          batch_first=True\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        h0 = torch.zeros(1, batch_size, 16).requires_grad_().to(device)\n",
        "        c0 = torch.zeros(1, batch_size, 16).requires_grad_().to(device)\n",
        "\n",
        "        x, (_, _) = self.lstm1(x, (h0, c0))\n",
        "\n",
        "        h0 = torch.zeros(1, batch_size, 352).requires_grad_().to(device)\n",
        "        c0 = torch.zeros(1, batch_size, 352).requires_grad_().to(device)\n",
        "        x, (_, _) = self.lstm2(x, (h0, c0))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MSGxKz99Cml"
      },
      "outputs": [],
      "source": [
        "### mine\n",
        "class decoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # First LSTM layer (added for symmetry with the encoder)\n",
        "        self.lstm1 = torch.nn.LSTM(\n",
        "            input_size=8,\n",
        "            hidden_size=16,\n",
        "            batch_first=True,\n",
        "            num_layers=1\n",
        "        )\n",
        "\n",
        "        # Second LSTM layer\n",
        "        self.lstm2 = torch.nn.LSTM(\n",
        "            input_size=16,\n",
        "            hidden_size=32,\n",
        "            batch_first=True,\n",
        "            num_layers=1\n",
        "        )\n",
        "\n",
        "        # Third LSTM layer\n",
        "        self.lstm3 = torch.nn.LSTM(\n",
        "            input_size=32,\n",
        "            hidden_size=353,\n",
        "            batch_first=True,\n",
        "            num_layers=1\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        # Initial hidden and cell states for lstm1\n",
        "        h0 = torch.zeros(1, batch_size, 16).requires_grad_().to(device)\n",
        "        c0 = torch.zeros(1, batch_size, 16).requires_grad_().to(device)\n",
        "        x, (_, _) = self.lstm1(x, (h0, c0))\n",
        "\n",
        "        # Initial hidden and cell states for lstm2\n",
        "        h0 = torch.zeros(1, batch_size, 32).requires_grad_().to(device)\n",
        "        c0 = torch.zeros(1, batch_size, 32).requires_grad_().to(device)\n",
        "        x, (_, _) = self.lstm2(x, (h0, c0))\n",
        "\n",
        "        # Initial hidden and cell states for lstm3\n",
        "        h0 = torch.zeros(1, batch_size, 353).requires_grad_().to(device)\n",
        "        c0 = torch.zeros(1, batch_size, 353).requires_grad_().to(device)\n",
        "        x, (_, _) = self.lstm3(x, (h0, c0))\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeHDksdoLOw3"
      },
      "outputs": [],
      "source": [
        "############### mine for add h,c\n",
        "# class encoder(torch.nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "\n",
        "#         self.lstm1 = torch.nn.LSTM(\n",
        "#             input_size=352,\n",
        "#             hidden_size=32,\n",
        "#             batch_first=True,\n",
        "#             num_layers=1\n",
        "#         )\n",
        "#         self.lstm2 = torch.nn.LSTM(\n",
        "#           input_size=32,\n",
        "#           hidden_size=8,\n",
        "#           num_layers=1,\n",
        "#           batch_first=True\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         batch_size = x.shape[0]\n",
        "#         h0 = torch.zeros(1, batch_size, 32).requires_grad_().to(device)\n",
        "#         c0 = torch.zeros(1, batch_size, 32).requires_grad_().to(device)\n",
        "\n",
        "#         x, (_, _) = self.lstm1(x, (h0, c0))\n",
        "\n",
        "#         h0 = torch.zeros(1, batch_size,8).requires_grad_().to(device)\n",
        "#         c0 = torch.zeros(1, batch_size, 8).requires_grad_().to(device)\n",
        "#         x, (_, _) = self.lstm2(x, (h0, c0))\n",
        "#         return x[:, :, :]\n",
        "\n",
        "class encoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # First LSTM layer\n",
        "        self.lstm1 = torch.nn.LSTM(\n",
        "            input_size=353,\n",
        "            hidden_size=32,  # Increased the hidden size for this example\n",
        "            batch_first=True,\n",
        "            num_layers=1\n",
        "        )\n",
        "\n",
        "        # Second LSTM layer\n",
        "        self.lstm2 = torch.nn.LSTM(\n",
        "            input_size=32,   # Input size matches the hidden size of lstm1\n",
        "            hidden_size=16,\n",
        "            batch_first=True,\n",
        "            num_layers=1\n",
        "        )\n",
        "\n",
        "        # Third LSTM layer (newly added)\n",
        "        self.lstm3 = torch.nn.LSTM(\n",
        "            input_size=16,   # Input size matches the hidden size of lstm2\n",
        "            hidden_size=8,\n",
        "            batch_first=True,\n",
        "            num_layers=1\n",
        "        )\n",
        "        self.h_proj_1_to_2 = torch.nn.Linear(32, 16)\n",
        "        self.c_proj_1_to_2 = torch.nn.Linear(32, 16)\n",
        "\n",
        "        self.h_proj_2_to_3 = torch.nn.Linear(16, 8)\n",
        "        self.c_proj_2_to_3 = torch.nn.Linear(16, 8)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        # Initial hidden and cell states for lstm1\n",
        "        # h0 = torch.zeros(1, batch_size, 32).requires_grad_().to(device)\n",
        "        # c0 = torch.zeros(1, batch_size, 32).requires_grad_().to(device)\n",
        "        # x, (_, _) = self.lstm1(x, (h0, c0))\n",
        "\n",
        "        # # Initial hidden and cell states for lstm2\n",
        "        # h0 = torch.zeros(1, batch_size, 16).requires_grad_().to(device)\n",
        "        # c0 = torch.zeros(1, batch_size, 16).requires_grad_().to(device)\n",
        "        # x, (_, _) = self.lstm2(x, (h0, c0))\n",
        "\n",
        "        # # Initial hidden and cell states for lstm3\n",
        "        # h0 = torch.zeros(1, batch_size, 8).requires_grad_().to(device)\n",
        "        # c0 = torch.zeros(1, batch_size, 8).requires_grad_().to(device)\n",
        "        # x, (_, _) = self.lstm3(x, (h0, c0))\n",
        "\n",
        "        ###### parisa changes of model give h , c to new layaer\n",
        "\n",
        "        # Initial hidden and cell states for lstm1\n",
        "        # Initial hidden and cell states for lstm1\n",
        "        h0 = torch.zeros(1, batch_size, 32).to(x.device)\n",
        "        c0 = torch.zeros(1, batch_size, 32).to(x.device)\n",
        "        x, (h1, c1) = self.lstm1(x, (h0, c0))\n",
        "\n",
        "        # Resize h1, c1 to match the input size of lstm2\n",
        "        h1 = self.h_proj_1_to_2(h1)\n",
        "        c1 = self.c_proj_1_to_2(c1)\n",
        "        x, (h2, c2) = self.lstm2(x, (h1, c1))\n",
        "\n",
        "        # Resize h2, c2 to match the input size of lstm3\n",
        "        h2 = self.h_proj_2_to_3(h2)\n",
        "        c2 = self.c_proj_2_to_3(c2)\n",
        "        x, (h3, c3) = self.lstm3(x, (h2, c2))\n",
        "        return x[:, :, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkWYYDUuLOw5"
      },
      "outputs": [],
      "source": [
        "### mine for add h,c\n",
        "class decoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # First LSTM layer (added for symmetry with the encoder)\n",
        "        self.lstm1 = torch.nn.LSTM(\n",
        "            input_size=8,\n",
        "            hidden_size=16,\n",
        "            batch_first=True,\n",
        "            num_layers=1\n",
        "        )\n",
        "\n",
        "        # Second LSTM layer\n",
        "        self.lstm2 = torch.nn.LSTM(\n",
        "            input_size=16,\n",
        "            hidden_size=32,\n",
        "            batch_first=True,\n",
        "            num_layers=1\n",
        "        )\n",
        "\n",
        "        # Third LSTM layer\n",
        "        self.lstm3 = torch.nn.LSTM(\n",
        "            input_size=32,\n",
        "            hidden_size=353,\n",
        "            batch_first=True,\n",
        "            num_layers=1\n",
        "        )\n",
        "\n",
        "        self.h_proj_1_to_2 = torch.nn.Linear(16, 32)\n",
        "        self.c_proj_1_to_2 = torch.nn.Linear(16, 32)\n",
        "\n",
        "        self.h_proj_2_to_3 = torch.nn.Linear(32, 353)\n",
        "        self.c_proj_2_to_3 = torch.nn.Linear(32, 353)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        # # Initial hidden and cell states for lstm1\n",
        "        # h0 = torch.zeros(1, batch_size, 16).requires_grad_().to(device)\n",
        "        # c0 = torch.zeros(1, batch_size, 16).requires_grad_().to(device)\n",
        "        # x, (_, _) = self.lstm1(x, (h0, c0))\n",
        "\n",
        "        # # Initial hidden and cell states for lstm2\n",
        "        # h0 = torch.zeros(1, batch_size, 32).requires_grad_().to(device)\n",
        "        # c0 = torch.zeros(1, batch_size, 32).requires_grad_().to(device)\n",
        "        # x, (_, _) = self.lstm2(x, (h0, c0))\n",
        "\n",
        "        # # Initial hidden and cell states for lstm3\n",
        "        # h0 = torch.zeros(1, batch_size, 352).requires_grad_().to(device)\n",
        "        # c0 = torch.zeros(1, batch_size, 352).requires_grad_().to(device)\n",
        "        # x, (_, _) = self.lstm3(x, (h0, c0))\n",
        "\n",
        "\n",
        "        ###### parisa changes of model give h , c to new layaer\n",
        "\n",
        "        # Initial hidden and cell states for lstm1\n",
        "        h1 = torch.zeros(1, batch_size, 16).to(x.device)\n",
        "        c1 = torch.zeros(1, batch_size, 16).to(x.device)\n",
        "        x, (h1, c1) = self.lstm1(x, (h1, c1))\n",
        "\n",
        "        # Resize h1, c1 to match the input size of lstm2\n",
        "        h2 = self.h_proj_1_to_2(h1)\n",
        "        c2 = self.c_proj_1_to_2(c1)\n",
        "        x, (h2, c2) = self.lstm2(x, (h2, c2))\n",
        "\n",
        "        # Resize h2, c2 to match the input size of lstm3\n",
        "        h3 = self.h_proj_2_to_3(h2)\n",
        "        c3 = self.c_proj_2_to_3(c2)\n",
        "        x, (h3, c3) = self.lstm3(x, (h3, c3))\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_cHUoGUQu07"
      },
      "outputs": [],
      "source": [
        "class AE(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder().to(device)\n",
        "        self.decoder = decoder().to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLe9AlzgQu08"
      },
      "outputs": [],
      "source": [
        "class RUAD(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder().to(device)\n",
        "        self.fc1 = torch.nn.Linear(8,16)\n",
        "        self.fc2 = torch.nn.Linear(16,353)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        #print('LSTM out', x.shape)\n",
        "        x = self.fc1(x)\n",
        "        #print('DENSE 1', x.shape)\n",
        "        x = self.fc2(x)\n",
        "        #print('DENSE 2', x.shape)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrkfnO0P86Ot"
      },
      "outputs": [],
      "source": [
        "#### mine\n",
        "# class RUAD(torch.nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "\n",
        "#         self.encoder = encoder().to(device)\n",
        "#         self.fc1 = torch.nn.Linear(8,16)\n",
        "#         self.fc2 = torch.nn.Linear(16,352)\n",
        "\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.encoder(x)\n",
        "#         #print('LSTM out', x.shape)\n",
        "#         x = self.fc1(x)\n",
        "#         #print('DENSE 1', x.shape)\n",
        "#         x = self.fc2(x)\n",
        "#         #print('DENSE 2', x.shape)\n",
        "\n",
        "#         return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKtcGAZu8-5z"
      },
      "outputs": [],
      "source": [
        "### mine\n",
        "class RUAD(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder().to(device)\n",
        "        self.fc1 = torch.nn.Linear(8, 16)\n",
        "        self.fc2 = torch.nn.Linear(16, 8)\n",
        "        self.decoder = decoder().to(device)  # Adding the decoder to RUAD\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        # Passing through the fully connected layers   ----- new changes\n",
        "        # x = self.fc1(x)\n",
        "        # x = self.fc2(x)\n",
        "        # Passing the result through the decoder ------- end of new changes\n",
        "        x = self.decoder(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOfd8fWLQu08"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eZVG4bFQu08",
        "outputId": "30d0667d-3f81-4361-c6f2-67d13eb96ea4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RUAD(\n",
              "  (encoder): encoder(\n",
              "    (lstm1): LSTM(353, 32, batch_first=True)\n",
              "    (lstm2): LSTM(32, 16, batch_first=True)\n",
              "    (lstm3): LSTM(16, 8, batch_first=True)\n",
              "    (h_proj_1_to_2): Linear(in_features=32, out_features=16, bias=True)\n",
              "    (c_proj_1_to_2): Linear(in_features=32, out_features=16, bias=True)\n",
              "    (h_proj_2_to_3): Linear(in_features=16, out_features=8, bias=True)\n",
              "    (c_proj_2_to_3): Linear(in_features=16, out_features=8, bias=True)\n",
              "  )\n",
              "  (fc1): Linear(in_features=8, out_features=16, bias=True)\n",
              "  (fc2): Linear(in_features=16, out_features=8, bias=True)\n",
              "  (decoder): decoder(\n",
              "    (lstm1): LSTM(8, 16, batch_first=True)\n",
              "    (lstm2): LSTM(16, 32, batch_first=True)\n",
              "    (lstm3): LSTM(32, 353, batch_first=True)\n",
              "    (h_proj_1_to_2): Linear(in_features=16, out_features=32, bias=True)\n",
              "    (c_proj_1_to_2): Linear(in_features=16, out_features=32, bias=True)\n",
              "    (h_proj_2_to_3): Linear(in_features=32, out_features=353, bias=True)\n",
              "    (c_proj_2_to_3): Linear(in_features=32, out_features=353, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "model = RUAD()\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iL-wSQFNQu08"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)  ### adam ro bezar va bebin\n",
        "criterion = torch.nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVZcvSKOQu08",
        "outputId": "fac3851c-2f6b-4e97-a787-515b17da0884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "torch.Size([1, 20, 353])\n",
            "torch.Size([1, 1, 353])\n"
          ]
        }
      ],
      "source": [
        "for d in train_loader:\n",
        "    print(len(d[0]))\n",
        "    print(d[0][0].size())\n",
        "    print(d[1].size())\n",
        "    break\n",
        "    ## batch size,(row count,column count) --> sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQEClIx2c8P4",
        "outputId": "1df382f1-bb3a-4208-f445-b444fb0f53f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RUAD(\n",
            "  (encoder): encoder(\n",
            "    (lstm1): LSTM(353, 32, batch_first=True)\n",
            "    (lstm2): LSTM(32, 16, batch_first=True)\n",
            "    (lstm3): LSTM(16, 8, batch_first=True)\n",
            "    (h_proj_1_to_2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (c_proj_1_to_2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (h_proj_2_to_3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (c_proj_2_to_3): Linear(in_features=16, out_features=8, bias=True)\n",
            "  )\n",
            "  (fc1): Linear(in_features=8, out_features=16, bias=True)\n",
            "  (fc2): Linear(in_features=16, out_features=8, bias=True)\n",
            "  (decoder): decoder(\n",
            "    (lstm1): LSTM(8, 16, batch_first=True)\n",
            "    (lstm2): LSTM(16, 32, batch_first=True)\n",
            "    (lstm3): LSTM(32, 353, batch_first=True)\n",
            "    (h_proj_1_to_2): Linear(in_features=16, out_features=32, bias=True)\n",
            "    (c_proj_1_to_2): Linear(in_features=16, out_features=32, bias=True)\n",
            "    (h_proj_2_to_3): Linear(in_features=32, out_features=353, bias=True)\n",
            "    (c_proj_2_to_3): Linear(in_features=32, out_features=353, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tt9nQfh2Qu09",
        "outputId": "0c8b1f10-b1e4-487d-f550-de32f00750c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01, Loss: 0.0042\n",
            "Epoch: 02, Loss: 0.0035\n",
            "Epoch: 03, Loss: 0.0061\n",
            "Epoch: 04, Loss: 0.0053\n",
            "Epoch: 05, Loss: 0.0214\n",
            "Epoch: 06, Loss: 0.0109\n",
            "CPU times: user 26min 13s, sys: 14.2 s, total: 26min 27s\n",
            "Wall time: 26min 46s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "def train():\n",
        "    model.train()\n",
        "    for d in train_loader:\n",
        "        #print(type(d))\n",
        "        x = d[0][0].to(device)\n",
        "        y = d[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x)\n",
        "        # print(out[0][9])\n",
        "        loss = criterion(out[0][train_window-1], y[0][0])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return float(loss)\n",
        "\n",
        "for epoch in range(6):\n",
        "    loss = train()\n",
        "    print(f'Epoch: {epoch+1:02d}, Loss: {loss:.4f}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "############ results\n",
        "########### result change layer 8 to 32\n",
        "# Epoch: 01, Loss: 0.0188\n",
        "# Epoch: 02, Loss: 0.0273\n",
        "# Epoch: 03, Loss: 0.0033\n",
        "# CPU times: user 6min 3s, sys: 3.62 s, total: 6min 6s\n",
        "# Wall time: 6min 12s\n",
        "\n",
        "########### result add hidden ayer 32\n",
        "# Epoch: 01, Loss: 0.0021\n",
        "# Epoch: 02, Loss: 0.0378\n",
        "# Epoch: 03, Loss: 0.0069\n",
        "# CPU times: user 7min 58s, sys: 4.28 s, total: 8min 2s\n",
        "# Wall time: 8min 11s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model with gpu\n",
        "# Epoch: 01, Loss: 0.0200\n",
        "# Epoch: 02, Loss: 0.0210\n",
        "# Epoch: 03, Loss: 0.0231\n",
        "# CPU times: user 13min 7s, sys: 14.9 s, total: 13min 22s\n",
        "# Wall time: 13min 5s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu\n",
        "# Epoch: 01, Loss: 0.0089\n",
        "# Epoch: 02, Loss: 0.0483\n",
        "# Epoch: 03, Loss: 0.0035\n",
        "# CPU times: user 12min 38s, sys: 13.5 s, total: 12min 51s\n",
        "# Wall time: 12min 34s\n",
        "\n",
        "########### result first ruad model with gpu and add timestamp column and window 10 and seq\n",
        "# Epoch: 01, Loss: 0.0107\n",
        "# Epoch: 02, Loss: 0.0098\n",
        "# Epoch: 03, Loss: 0.0219\n",
        "# CPU times: user 11min 17s, sys: 4.6 s, total: 11min 22s\n",
        "# Wall time: 11min 28s\n",
        "\n",
        "########### result first ruad model with gpu and add timestamp column and window 10 and remove seq\n",
        "# Epoch: 01, Loss: 0.0252\n",
        "# Epoch: 02, Loss: 0.0093\n",
        "# Epoch: 03, Loss: 0.0188\n",
        "# CPU times: user 11min 8s, sys: 4.67 s, total: 11min 12s\n",
        "# Wall time: 11min 19s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 10 and remove seq , adam optimizer\n",
        "# Epoch: 01, Loss: 0.0365\n",
        "# Epoch: 02, Loss: 0.0473\n",
        "# Epoch: 03, Loss: 0.0536\n",
        "# CPU times: user 12min 14s, sys: 13.8 s, total: 12min 28s\n",
        "# Wall time: 12min 12s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 10 and remove seq , SGD optimizer\n",
        "# Epoch: 01, Loss: 0.0594\n",
        "# Epoch: 02, Loss: 0.0260\n",
        "# Epoch: 03, Loss: 0.0311\n",
        "# CPU times: user 11min 27s, sys: 13.3 s, total: 11min 40s\n",
        "# Wall time: 11min 24s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 10 and remove seq , SGD optimizer, epoch 8\n",
        "# Epoch: 01, Loss: 0.0270\n",
        "# Epoch: 02, Loss: 0.0267\n",
        "# Epoch: 03, Loss: 0.0317\n",
        "# Epoch: 04, Loss: 0.0313\n",
        "# Epoch: 05, Loss: 0.0615\n",
        "# CPU times: user 19min 21s, sys: 23.7 s, total: 19min 44s\n",
        "# Wall time: 19min 18s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 10 and remove seq , SGD optimizer, epoch 5 , add h,c\n",
        "# Epoch: 01, Loss: 0.0211\n",
        "# Epoch: 02, Loss: 0.0153\n",
        "# Epoch: 03, Loss: 0.0244\n",
        "# Epoch: 04, Loss: 0.0031\n",
        "# Epoch: 05, Loss: 0.0129\n",
        "# CPU times: user 20min 12s, sys: 12 s, total: 20min 24s\n",
        "# Wall time: 20min 39s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 10 and remove seq , SGD optimizer, epoch 6 , add h,c\n",
        "# Epoch: 01, Loss: 0.0211\n",
        "# Epoch: 02, Loss: 0.0153\n",
        "# Epoch: 03, Loss: 0.0244\n",
        "# Epoch: 04, Loss: 0.0031\n",
        "# Epoch: 05, Loss: 0.0129\n",
        "# Epoch: 06, Loss: 0.0030\n",
        "# CPU times: user 24min 16s, sys: 14.37 s, total: 24min 30s\n",
        "# Wall time: 24min 48s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 20 and remove seq , SGD optimizer, epoch 6 , add h,c\n",
        "# Epoch: 01, Loss: 0.0042\n",
        "# Epoch: 02, Loss: 0.0035\n",
        "# Epoch: 03, Loss: 0.0061\n",
        "# Epoch: 04, Loss: 0.0053\n",
        "# Epoch: 05, Loss: 0.0214\n",
        "# Epoch: 06, Loss: 0.0109\n",
        "# CPU times: user 26min 13s, sys: 14.2 s, total: 26min 27s\n",
        "# Wall time: 26min 46s\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogU-wULvQu09"
      },
      "outputs": [],
      "source": [
        "def test(x):\n",
        "    model.eval()\n",
        "    x = x.to(device)\n",
        "    out = model(x)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AznBaZd9Qu09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff554d80-18bc-410b-8f59-92b45727fbe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ],
      "source": [
        "X, y = next(iter(test_loader))\n",
        "#print(X.shape)\n",
        "print(len(X[0][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PD4G2hAlQu09"
      },
      "outputs": [],
      "source": [
        "out = test(X[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIJkCCKdQu0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78ca67eb-1dec-441f-b6c1-9251bf2b78b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 353])\n"
          ]
        }
      ],
      "source": [
        "for d in test_loader:\n",
        "    print(d[0][0].size())\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbDh2hGvQu0-"
      },
      "outputs": [],
      "source": [
        "for d in test_loader:\n",
        "    x = d[0][0].to(device)\n",
        "    y = d[1].to(device)\n",
        "    out = model(x)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHNcfzkSQu0-"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error,roc_auc_score\n",
        "reconstruction = []\n",
        "loss = []\n",
        "#y_true = []\n",
        "for d in test_loader:\n",
        "    x = d[0][0]\n",
        "    y = d[1]\n",
        "    out = test(x)\n",
        "    reconstruction.append(out)\n",
        "    loss.append(mean_squared_error(out[0][train_window-1].detach().cpu().numpy(),y[0][0]))\n",
        "    #y_true.append(d[1].detach().cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LYPX4CKQu0-"
      },
      "outputs": [],
      "source": [
        "# test_seq_label = create_data_seq(test_labels,train_window,revelent_len)\n",
        "test_seq_label = create_data_seq(test_labels,train_window)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJaVsXaAQu0_"
      },
      "outputs": [],
      "source": [
        "temp_list = []\n",
        "for i in range(len(test_seq_label)):\n",
        "    temp = test_seq_label[i][1].type(torch.int64)\n",
        "    temp = temp.detach().cpu().numpy().tolist()\n",
        "    temp_list.append(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-WZzWbjQu0_"
      },
      "outputs": [],
      "source": [
        "y_true = []\n",
        "for i in range(len(temp_list)):\n",
        "    y_true.append(temp_list[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHHG9P2BQu0_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "d50e179f-f85e-4817-c57a-6338deca61d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               loss    true_class\n",
              "count  10442.000000  10442.000000\n",
              "mean       0.016721      0.013120\n",
              "std        0.039142      0.113795\n",
              "min        0.002611      0.000000\n",
              "25%        0.006026      0.000000\n",
              "50%        0.008819      0.000000\n",
              "75%        0.015921      0.000000\n",
              "max        0.295949      1.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9abcbd43-50d7-466f-a183-a2c6f2d585e5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>true_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10442.000000</td>\n",
              "      <td>10442.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.016721</td>\n",
              "      <td>0.013120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.039142</td>\n",
              "      <td>0.113795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.002611</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.006026</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.008819</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.015921</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.295949</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9abcbd43-50d7-466f-a183-a2c6f2d585e5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9abcbd43-50d7-466f-a183-a2c6f2d585e5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9abcbd43-50d7-466f-a183-a2c6f2d585e5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-21c9137f-9707-41c5-8cd4-46c413054c1d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-21c9137f-9707-41c5-8cd4-46c413054c1d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-21c9137f-9707-41c5-8cd4-46c413054c1d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"error_df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3691.785050906971,\n        \"min\": 0.002610740251839161,\n        \"max\": 10442.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.01672135666012764,\n          0.008819221518933773,\n          10442.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"true_class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3691.7476028831948,\n        \"min\": 0.0,\n        \"max\": 10442.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.013120091936410649,\n          1.0,\n          0.11379453075958086\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "error_df = pd.DataFrame({'loss': loss,\n",
        "                        'true_class': y_true})\n",
        "error_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9ilQ6bBQu0_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d2a5941-dab6-4940-eff9-88439056b3fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9069957536027086"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(error_df['true_class'],error_df['loss'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#0.8765328998395648\n",
        "#0.8723729179726375    result of change hidden layer from 8 to 32\n",
        "#0.9065247187071686    result of add one layer 32 between encoder :)\n",
        "######0.904416749009233     result add hidden layer 32 to decoder too and add decoder to ruad model with gpu (this is pretty good)   ----- moshtrak\n",
        "#####0.8655186444515994    result first ruad model with gpu and add timestamp column and woindow 10 and seq , adam optimizer\n",
        "#0.8967381497429511    result first ruad model with gpu and add timestamp column and woindow 10 and remove seq , adam optimizer\n",
        "#0.3060959342747257    result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 10 and remove seq, adam optimizer\n",
        "#0.34766214604908874   result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 10 and remove seq, SGD optimizer\n",
        "#0.36209899126422795   result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 10 and remove seq, SGD optimizer , epoch 5 +3 (i forgot to reset)\n",
        "#0.907213292243243     result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 10 and remove seq, SGD optimizer , epoch 5 , add , h,c\n",
        "#0.9098181020482538    result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 10 and remove seq, SGD optimizer , epoch 6 , add , h,c\n",
        "#0.9069957536027086    result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu window 20 and remove seq, SGD optimizer , epoch 6 , add , h,c"
      ],
      "metadata": {
        "id": "0H5GYfJ0T5xq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}