{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXJOdzIXQu0z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.transforms import ToTensor\n",
        "from pandas import Series\n",
        "import numpy as np\n",
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofAfliT7WRP4"
      },
      "outputs": [],
      "source": [
        "#The dataset, collected on the Marconi 100 system, has been published and\n",
        "#described in the Scientific dataset publication: https://www.nature.com/articles/s41597-023-02174-3\n",
        "#It is available on Zenodo: https://zenodo.org/records/7541722\n",
        "\n",
        "\n",
        "#This is rack 1 of the dataset\n",
        "!wget https://zenodo.org/record/7541722/files/1.tar?download=1 -o rack.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4NUMrbtXOIt"
      },
      "outputs": [],
      "source": [
        "!tar -xf /content/1.tar?download=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XGtDIafQu00"
      },
      "outputs": [],
      "source": [
        "#This is node 36, of rack 1\n",
        "file_name = '36.parquet'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "ZDXmjiSqQu01",
        "outputId": "35daebc2-e21f-4715-e967-ab136e137516"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  timestamp  ambient_avg  ambient_std  ambient_min  \\\n",
              "0 2020-03-09 12:00:00+00:00    21.636362     0.077138    21.600000   \n",
              "1 2020-03-09 12:15:00+00:00    21.860000     0.128063    21.600000   \n",
              "2 2020-03-09 12:30:00+00:00    21.885714     0.098975    21.799999   \n",
              "3 2020-03-09 12:45:00+00:00    21.918917     0.098194    21.799999   \n",
              "4 2020-03-09 13:00:00+00:00    21.875553     0.096967    21.799999   \n",
              "\n",
              "   ambient_max  dimm0_temp_avg  dimm0_temp_std  dimm0_temp_min  \\\n",
              "0    21.799999            29.0             0.0            29.0   \n",
              "1    22.000000            29.0             0.0            29.0   \n",
              "2    22.000000            29.0             0.0            29.0   \n",
              "3    22.000000            29.0             0.0            29.0   \n",
              "4    22.000000            29.0             0.0            29.0   \n",
              "\n",
              "   dimm0_temp_max  dimm10_temp_avg  ...  ps1_output_curre_max  \\\n",
              "0            29.0             30.0  ...                  22.0   \n",
              "1            29.0             30.0  ...                  21.0   \n",
              "2            29.0             30.0  ...                  21.0   \n",
              "3            29.0             30.0  ...                  20.0   \n",
              "4            29.0             30.0  ...                  21.0   \n",
              "\n",
              "   ps1_output_volta_avg  ps1_output_volta_std  ps1_output_volta_min  \\\n",
              "0             12.399999                   0.0                  12.4   \n",
              "1             12.399998                   0.0                  12.4   \n",
              "2             12.399999                   0.0                  12.4   \n",
              "3             12.399999                   0.0                  12.4   \n",
              "4             12.400001                   0.0                  12.4   \n",
              "\n",
              "   ps1_output_volta_max  total_power_avg  total_power_std  total_power_min  \\\n",
              "0                  12.4            400.0              0.0            400.0   \n",
              "1                  12.4            400.0              0.0            400.0   \n",
              "2                  12.4            400.0              0.0            400.0   \n",
              "3                  12.4            400.0              0.0            400.0   \n",
              "4                  12.4            400.0              0.0            400.0   \n",
              "\n",
              "   total_power_max  value  \n",
              "0            400.0   <NA>  \n",
              "1            400.0   <NA>  \n",
              "2            400.0   <NA>  \n",
              "3            400.0   <NA>  \n",
              "4            400.0   <NA>  \n",
              "\n",
              "[5 rows x 354 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de80a67f-327f-4229-a7a8-33d5146eb69a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>ambient_avg</th>\n",
              "      <th>ambient_std</th>\n",
              "      <th>ambient_min</th>\n",
              "      <th>ambient_max</th>\n",
              "      <th>dimm0_temp_avg</th>\n",
              "      <th>dimm0_temp_std</th>\n",
              "      <th>dimm0_temp_min</th>\n",
              "      <th>dimm0_temp_max</th>\n",
              "      <th>dimm10_temp_avg</th>\n",
              "      <th>...</th>\n",
              "      <th>ps1_output_curre_max</th>\n",
              "      <th>ps1_output_volta_avg</th>\n",
              "      <th>ps1_output_volta_std</th>\n",
              "      <th>ps1_output_volta_min</th>\n",
              "      <th>ps1_output_volta_max</th>\n",
              "      <th>total_power_avg</th>\n",
              "      <th>total_power_std</th>\n",
              "      <th>total_power_min</th>\n",
              "      <th>total_power_max</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-03-09 12:00:00+00:00</td>\n",
              "      <td>21.636362</td>\n",
              "      <td>0.077138</td>\n",
              "      <td>21.600000</td>\n",
              "      <td>21.799999</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>...</td>\n",
              "      <td>22.0</td>\n",
              "      <td>12.399999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.4</td>\n",
              "      <td>12.4</td>\n",
              "      <td>400.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-03-09 12:15:00+00:00</td>\n",
              "      <td>21.860000</td>\n",
              "      <td>0.128063</td>\n",
              "      <td>21.600000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>...</td>\n",
              "      <td>21.0</td>\n",
              "      <td>12.399998</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.4</td>\n",
              "      <td>12.4</td>\n",
              "      <td>400.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-03-09 12:30:00+00:00</td>\n",
              "      <td>21.885714</td>\n",
              "      <td>0.098975</td>\n",
              "      <td>21.799999</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>...</td>\n",
              "      <td>21.0</td>\n",
              "      <td>12.399999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.4</td>\n",
              "      <td>12.4</td>\n",
              "      <td>400.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-03-09 12:45:00+00:00</td>\n",
              "      <td>21.918917</td>\n",
              "      <td>0.098194</td>\n",
              "      <td>21.799999</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>...</td>\n",
              "      <td>20.0</td>\n",
              "      <td>12.399999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.4</td>\n",
              "      <td>12.4</td>\n",
              "      <td>400.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-03-09 13:00:00+00:00</td>\n",
              "      <td>21.875553</td>\n",
              "      <td>0.096967</td>\n",
              "      <td>21.799999</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>...</td>\n",
              "      <td>21.0</td>\n",
              "      <td>12.400001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.4</td>\n",
              "      <td>12.4</td>\n",
              "      <td>400.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>400.0</td>\n",
              "      <td>&lt;NA&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 354 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de80a67f-327f-4229-a7a8-33d5146eb69a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-de80a67f-327f-4229-a7a8-33d5146eb69a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-de80a67f-327f-4229-a7a8-33d5146eb69a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7344025c-0fef-45e5-9573-26fc5085d1ee\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7344025c-0fef-45e5-9573-26fc5085d1ee')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7344025c-0fef-45e5-9573-26fc5085d1ee button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "DATA"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "DATA = pd.read_parquet(file_name)\n",
        "DATA.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA.columns\n",
        "\n",
        "f = open(\"column_names_of_data.txt\", \"a\")\n",
        "for item in DATA.columns:\n",
        "  f.write(item)\n",
        "  f.write(\"\\n\")\n",
        "\n",
        "f.close()"
      ],
      "metadata": {
        "id": "m7AxzhKTVTNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiFEl64MUX7u"
      },
      "outputs": [],
      "source": [
        "#The dataset has periods of unavailability of Nagios traces, as described in the dataset paper:  https://www.nature.com/articles/s41597-023-02174-3/figures/3\n",
        "#We suggest dropping the periods where the labels are largely unavailable and using the dataset either after 1.4.2021 or 1.10.2021.\n",
        "DATA = DATA[DATA['timestamp'] > '2021-04-01']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQkJAI-cNPUG"
      },
      "outputs": [],
      "source": [
        "DATA.reset_index(drop=True, inplace = True)\n",
        "DATA = DATA.fillna(0)\n",
        "DATA['timestamp'] = pd.to_datetime(DATA['timestamp'])\n",
        "l = DATA.timestamp.diff() == pd.Timedelta(minutes=15) #time consistency -> measurements should be 15 minutes apart\n",
        "chunks = []\n",
        "current_chunk = []\n",
        "for index, value in enumerate(l):\n",
        "    current_chunk.append(DATA.iloc[index])\n",
        "    if not value:\n",
        "        chunks.append(pd.DataFrame(current_chunk))\n",
        "        current_chunk = []\n",
        "\n",
        "\n",
        "if current_chunk:\n",
        "    chunks.append(pd.DataFrame(current_chunk))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA['value'] = DATA['value'].replace(2,1)\n",
        "DATA['value'] = DATA['value'].replace(3,1)\n",
        "relevant = [c for c in chunks if len(c) >= 20] #assuming time window of 20\n",
        "DATA2 = pd.concat(relevant)\n",
        "DATA = DATA2\n",
        "DATA['value'] = DATA['value'].replace(2,1)\n",
        "DATA['value'] = DATA['value'].replace(3,1)\n",
        "DATA = DATA.drop(columns=['timestamp'])\n",
        "DATA = DATA.astype(float)"
      ],
      "metadata": {
        "id": "MWVL8xDF579k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2IMXqzoQu03"
      },
      "outputs": [],
      "source": [
        "scaler = preprocessing.MinMaxScaler()\n",
        "names = DATA.columns\n",
        "d = scaler.fit_transform(DATA)\n",
        "DATA = pd.DataFrame(d, columns=names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJlNWM1tQu03"
      },
      "outputs": [],
      "source": [
        "train_data = DATA[:int(DATA.shape[0]*0.8)]\n",
        "test_data = DATA[int(DATA.shape[0]*0.8):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiA7OH9WQu03",
        "outputId": "ab8c6430-7075-4583-c272-71b1d9191868"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((41847, 353), (10462, 353))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "train_data.shape,test_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWVtf7vpQu03",
        "outputId": "0a682884-f3b1-4500-d1a8-bdd9fa44dbfe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41847, 353)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "train_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "VUT7QzOKQu04",
        "outputId": "5dea2d94-501c-4a39-ccc1-5b429490d8ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "value\n",
              "0.0    40673\n",
              "1.0     1174\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>value</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>40673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>1174</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "train_data['value'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onXqoqEGQu04"
      },
      "outputs": [],
      "source": [
        " train_feat = train_data.drop(columns=['value'])\n",
        "train_feat = train_feat.to_numpy()\n",
        "test_feat = test_data.drop(columns=['value'])\n",
        "test_feat = test_feat.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TKEoNSjQu04"
      },
      "outputs": [],
      "source": [
        "train_feat = torch.tensor(train_feat, dtype=torch.float)\n",
        "test_feat = torch.tensor(test_feat, dtype=torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Of6oEPbQu05",
        "outputId": "ee7a0799-4704-484e-ba87-e8b5b73e9305"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0.,  ..., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "test_labels = test_data['value']\n",
        "test_labels = test_labels.to_numpy()\n",
        "test_labels = torch.tensor(test_labels, dtype=torch.float)\n",
        "test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlsEjPJ0Qu05"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z95V8uGGQu05"
      },
      "outputs": [],
      "source": [
        "train_window = 30 #20\n",
        "\n",
        "def create_data_seq(data,tw):\n",
        "    seq = []\n",
        "    for i in range(len(data)-tw):\n",
        "        x_seq = data[i:i+tw],\n",
        "        y_seq = data[i+tw:i+tw+1]  ###در ترین میاد 0 تا 20 رو میده و میگه 21 رو حدس بزن\n",
        "        seq.append((x_seq,y_seq))\n",
        "    return seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQND2EJuQu06"
      },
      "outputs": [],
      "source": [
        "train_seq = create_data_seq(train_feat,train_window)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xnsh7J1Qu06",
        "outputId": "d5175e15-bf91-4c5e-a73a-373c85b2aa50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[[0.5250, 0.0000, 0.5566,  ..., 0.5303, 0.3649, 0.8854],\n",
            "         [0.5250, 0.0000, 0.5566,  ..., 0.3876, 0.3649, 0.7917],\n",
            "         [0.5250, 0.0000, 0.5566,  ..., 0.4028, 0.3649, 0.9062],\n",
            "         ...,\n",
            "         [0.5289, 0.0120, 0.5566,  ..., 0.3187, 0.3514, 0.6979],\n",
            "         [0.5294, 0.0000, 0.5613,  ..., 0.5455, 0.3243, 0.9271],\n",
            "         [0.5271, 0.0208, 0.5566,  ..., 0.4750, 0.2703, 0.6354]]])]\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_seq, batch_size=1, shuffle=True)\n",
        "\n",
        "X,y = next(iter(train_loader))\n",
        "print(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = next(iter(train_loader))\n",
        "print(X)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkP0CqVFpEd7",
        "outputId": "90b6f82c-37b5-474e-f3a3-a71bcec4a8e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[[0.5199, 0.0130, 0.5472,  ..., 0.2773, 0.3514, 0.5833],\n",
            "         [0.5194, 0.0165, 0.5472,  ..., 0.1763, 0.3514, 0.4479],\n",
            "         [0.5184, 0.0191, 0.5472,  ..., 0.2711, 0.3514, 0.6354],\n",
            "         ...,\n",
            "         [0.5184, 0.0191, 0.5472,  ..., 0.0880, 0.3649, 0.4688],\n",
            "         [0.5187, 0.0188, 0.5472,  ..., 0.4300, 0.3514, 0.7708],\n",
            "         [0.5187, 0.0188, 0.5472,  ..., 0.3962, 0.3649, 0.8646]]])]\n",
            "tensor([[[0.5179, 0.0189, 0.5472, 0.4835, 0.6633, 0.0000, 0.6889, 0.6327,\n",
            "          0.6695, 0.0000, 0.6957, 0.6400, 0.6519, 0.0000, 0.6739, 0.6200,\n",
            "          0.6599, 0.0000, 0.6809, 0.6275, 0.6653, 0.0000, 0.7021, 0.6346,\n",
            "          0.6488, 0.0000, 0.6739, 0.6200, 0.6818, 0.0000, 0.7083, 0.6538,\n",
            "          0.6828, 0.0000, 0.7111, 0.6400, 0.6725, 0.1733, 0.6889, 0.6400,\n",
            "          0.6828, 0.0000, 0.7111, 0.6400, 0.6574, 0.0000, 0.6889, 0.6200,\n",
            "          0.6605, 0.0000, 0.6889, 0.6200, 0.6555, 0.0000, 0.6739, 0.6200,\n",
            "          0.6630, 0.0000, 0.6889, 0.6327, 0.6559, 0.0000, 0.6739, 0.6200,\n",
            "          0.6651, 0.0000, 0.6809, 0.6275, 0.4673, 0.0038, 0.5658, 0.3826,\n",
            "          0.4943, 0.0000, 0.5875, 0.4312, 0.4731, 0.0000, 0.5733, 0.3981,\n",
            "          0.4934, 0.0000, 0.5875, 0.4352, 0.4679, 0.0039, 0.5658, 0.4037,\n",
            "          0.4932, 0.0000, 0.5875, 0.4352, 0.4679, 0.0075, 0.5658, 0.4037,\n",
            "          0.4937, 0.0000, 0.5875, 0.4352, 0.1745, 0.0189, 0.2745, 0.1385,\n",
            "          0.6032, 0.0687, 0.5897, 0.6543, 0.5819, 0.0449, 0.5714, 0.5974,\n",
            "          0.5835, 0.0514, 0.5610, 0.6190, 0.5812, 0.0383, 0.5733, 0.5949,\n",
            "          0.5731, 0.0923, 0.5970, 0.5974, 0.5403, 0.0450, 0.5692, 0.5616,\n",
            "          0.5977, 0.0827, 0.5875, 0.6627, 0.6258, 0.0381, 0.6197, 0.6400,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.6280, 0.2340, 0.5797, 0.6849, 0.6488, 0.2654, 0.5970, 0.7000,\n",
            "          0.6089, 0.0332, 0.6087, 0.5972, 0.5950, 0.0354, 0.6000, 0.5946,\n",
            "          0.6028, 0.0306, 0.6087, 0.5890, 0.6154, 0.0332, 0.6176, 0.5972,\n",
            "          0.6156, 0.0329, 0.6176, 0.6056, 0.5977, 0.0302, 0.6000, 0.5972,\n",
            "          0.5957, 0.0304, 0.6000, 0.5811, 0.6064, 0.0305, 0.6087, 0.5890,\n",
            "          0.6164, 0.0352, 0.6143, 0.6081, 0.6135, 0.0404, 0.6143, 0.6053,\n",
            "          0.6497, 0.1472, 0.6056, 0.6579, 0.6622, 0.1790, 0.6232, 0.7027,\n",
            "          0.5919, 0.0349, 0.5882, 0.5833, 0.6000, 0.0369, 0.5970, 0.5833,\n",
            "          0.8036, 0.1406, 0.8281, 0.7308, 0.4171, 0.0963, 0.4286, 0.4286,\n",
            "          0.2059, 0.0614, 0.1485, 0.2296, 0.6820, 0.0105, 0.6875, 0.6538,\n",
            "          0.6083, 0.0378, 0.6000, 0.5942, 0.6211, 0.0433, 0.6190, 0.6212,\n",
            "          0.6353, 0.0448, 0.6393, 0.6308, 0.5953, 0.0359, 0.5909, 0.5857,\n",
            "          0.5881, 0.0330, 0.5909, 0.5857, 0.6108, 0.0368, 0.6094, 0.6119,\n",
            "          0.7543, 0.0749, 0.7656, 0.7571, 0.6532, 0.0535, 0.6508, 0.6515,\n",
            "          0.6341, 0.1623, 0.6094, 0.6765, 0.6188, 0.1762, 0.5909, 0.7059,\n",
            "          0.6854, 0.2638, 0.5970, 0.7391, 0.5834, 0.0402, 0.5714, 0.5833,\n",
            "          0.5788, 0.0381, 0.5714, 0.5833, 0.6039, 0.0455, 0.5821, 0.6087,\n",
            "          0.6086, 0.0412, 0.6000, 0.6269, 0.6101, 0.0404, 0.6000, 0.5942,\n",
            "          0.8108, 0.1549, 0.8361, 0.7368, 0.4193, 0.0942, 0.4500, 0.4444,\n",
            "          0.2211, 0.1276, 0.1313, 0.3731, 0.6676, 0.0344, 0.6667, 0.6538,\n",
            "          0.7956, 0.0164, 0.8023, 0.7814, 0.4053, 0.1568, 0.3704, 0.5978,\n",
            "          0.9795, 0.0269, 0.9828, 0.9829, 0.4012, 0.3508, 0.3390, 0.7949,\n",
            "          0.9841, 0.0024, 0.9839, 0.9919, 0.4320, 0.1842, 0.4048, 0.6186,\n",
            "          0.9827, 0.0000, 0.9829, 0.9746, 0.4036, 0.2420, 0.3710, 0.7342,\n",
            "          0.9839, 0.0000, 0.9839, 0.9839, 0.3626, 0.0536, 0.3649, 0.3854]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dC4Ja5rSQu06"
      },
      "outputs": [],
      "source": [
        "test_seq = create_data_seq(test_feat,train_window)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxlFxsRtQu06"
      },
      "outputs": [],
      "source": [
        "test_loader = DataLoader(test_seq, batch_size=1, shuffle=False) ## در هر فور ما یه تعدادی بچ داریم که میدیم به دل با بچ بیشتر میتونیم بگیم مثلا 2 تا 2 تا بهش بده\n",
        "X,y = next(iter(test_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDfQgT_hQu07"
      },
      "outputs": [],
      "source": [
        "class encoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.lstm1 = torch.nn.LSTM(\n",
        "            input_size=352,\n",
        "            hidden_size=16,\n",
        "            batch_first=True,\n",
        "            num_layers=1\n",
        "        )\n",
        "        self.lstm2 = torch.nn.LSTM(\n",
        "          input_size=16,\n",
        "          hidden_size=8,\n",
        "          num_layers=1,\n",
        "          batch_first=True\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        h0 = torch.zeros(1, batch_size, 16).requires_grad_().to(device)\n",
        "        c0 = torch.zeros(1, batch_size, 16).requires_grad_().to(device)\n",
        "\n",
        "        x, (_, _) = self.lstm1(x, (h0, c0))\n",
        "\n",
        "        h0 = torch.zeros(1, batch_size,8).requires_grad_().to(device)\n",
        "        c0 = torch.zeros(1, batch_size, 8).requires_grad_().to(device)\n",
        "        x, (_, _) = self.lstm2(x, (h0, c0))\n",
        "        return x[:, :, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWDhY2QLvvRO"
      },
      "outputs": [],
      "source": [
        "############### mine\n",
        "# class encoder(torch.nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "\n",
        "#         self.lstm1 = torch.nn.LSTM(\n",
        "#             input_size=352,\n",
        "#             hidden_size=32,\n",
        "#             batch_first=True,\n",
        "#             num_layers=1\n",
        "#         )\n",
        "#         self.lstm2 = torch.nn.LSTM(\n",
        "#           input_size=32,\n",
        "#           hidden_size=8,\n",
        "#           num_layers=1,\n",
        "#           batch_first=True\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         batch_size = x.shape[0]\n",
        "#         h0 = torch.zeros(1, batch_size, 32).requires_grad_().to(device)\n",
        "#         c0 = torch.zeros(1, batch_size, 32).requires_grad_().to(device)\n",
        "\n",
        "#         x, (_, _) = self.lstm1(x, (h0, c0))\n",
        "\n",
        "#         h0 = torch.zeros(1, batch_size,8).requires_grad_().to(device)\n",
        "#         c0 = torch.zeros(1, batch_size, 8).requires_grad_().to(device)\n",
        "#         x, (_, _) = self.lstm2(x, (h0, c0))\n",
        "#         return x[:, :, :]\n",
        "\n",
        "class encoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # First LSTM layer\n",
        "        self.lstm1 = torch.nn.LSTM(\n",
        "            input_size=352,\n",
        "            hidden_size=32,  # Increased the hidden size for this example\n",
        "            batch_first=True,\n",
        "            num_layers=1\n",
        "        )\n",
        "\n",
        "        # Second LSTM layer\n",
        "        self.lstm2 = torch.nn.LSTM(\n",
        "            input_size=32,   # Input size matches the hidden size of lstm1\n",
        "            hidden_size=16,\n",
        "            batch_first=True,\n",
        "            num_layers=1\n",
        "        )\n",
        "\n",
        "        # Third LSTM layer (newly added)\n",
        "        self.lstm3 = torch.nn.LSTM(\n",
        "            input_size=16,   # Input size matches the hidden size of lstm2\n",
        "            hidden_size=8,\n",
        "            batch_first=True,\n",
        "            num_layers=1\n",
        "        )\n",
        "        self.h_proj_1_to_2 = torch.nn.Linear(32, 16)\n",
        "        self.c_proj_1_to_2 = torch.nn.Linear(32, 16)\n",
        "\n",
        "        self.h_proj_2_to_3 = torch.nn.Linear(16, 8)\n",
        "        self.c_proj_2_to_3 = torch.nn.Linear(16, 8)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        # Initial hidden and cell states for lstm1\n",
        "        # h0 = torch.zeros(1, batch_size, 32).requires_grad_().to(device)\n",
        "        # c0 = torch.zeros(1, batch_size, 32).requires_grad_().to(device)\n",
        "        # x, (_, _) = self.lstm1(x, (h0, c0))\n",
        "\n",
        "        # # Initial hidden and cell states for lstm2\n",
        "        # h0 = torch.zeros(1, batch_size, 16).requires_grad_().to(device)\n",
        "        # c0 = torch.zeros(1, batch_size, 16).requires_grad_().to(device)\n",
        "        # x, (_, _) = self.lstm2(x, (h0, c0))\n",
        "\n",
        "        # # Initial hidden and cell states for lstm3\n",
        "        # h0 = torch.zeros(1, batch_size, 8).requires_grad_().to(device)\n",
        "        # c0 = torch.zeros(1, batch_size, 8).requires_grad_().to(device)\n",
        "        # x, (_, _) = self.lstm3(x, (h0, c0))\n",
        "\n",
        "        ###### parisa changes of model give h , c to new layaer\n",
        "\n",
        "        # Initial hidden and cell states for lstm1\n",
        "        # Initial hidden and cell states for lstm1\n",
        "        h0 = torch.zeros(1, batch_size, 32).to(x.device)\n",
        "        c0 = torch.zeros(1, batch_size, 32).to(x.device)\n",
        "        x, (h1, c1) = self.lstm1(x, (h0, c0))\n",
        "\n",
        "        # Resize h1, c1 to match the input size of lstm2\n",
        "        h1 = self.h_proj_1_to_2(h1)\n",
        "        c1 = self.c_proj_1_to_2(c1)\n",
        "        x, (h2, c2) = self.lstm2(x, (h1, c1))\n",
        "\n",
        "        # Resize h2, c2 to match the input size of lstm3\n",
        "        h2 = self.h_proj_2_to_3(h2)\n",
        "        c2 = self.c_proj_2_to_3(c2)\n",
        "        x, (h3, c3) = self.lstm3(x, (h2, c2))\n",
        "        return x[:, :, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TF38j7s0Qu07"
      },
      "outputs": [],
      "source": [
        "class decoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.lstm1 = torch.nn.LSTM(\n",
        "            input_size=8,\n",
        "            hidden_size=16,\n",
        "            batch_first=True,\n",
        "            num_layers=1\n",
        "        )\n",
        "        self.lstm2 = torch.nn.LSTM(\n",
        "          input_size=16,\n",
        "          hidden_size=352,\n",
        "          num_layers=1,\n",
        "          batch_first=True\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        h0 = torch.zeros(1, batch_size, 16).requires_grad_().to(device)\n",
        "        c0 = torch.zeros(1, batch_size, 16).requires_grad_().to(device)\n",
        "\n",
        "        x, (_, _) = self.lstm1(x, (h0, c0))\n",
        "\n",
        "        h0 = torch.zeros(1, batch_size, 352).requires_grad_().to(device)\n",
        "        c0 = torch.zeros(1, batch_size, 352).requires_grad_().to(device)\n",
        "        x, (_, _) = self.lstm2(x, (h0, c0))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MSGxKz99Cml"
      },
      "outputs": [],
      "source": [
        "### mine\n",
        "class decoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # First LSTM layer (added for symmetry with the encoder)\n",
        "        self.lstm1 = torch.nn.LSTM(\n",
        "            input_size=8,\n",
        "            hidden_size=16,\n",
        "            batch_first=True,\n",
        "            num_layers=1\n",
        "        )\n",
        "\n",
        "        # Second LSTM layer\n",
        "        self.lstm2 = torch.nn.LSTM(\n",
        "            input_size=16,\n",
        "            hidden_size=32,\n",
        "            batch_first=True,\n",
        "            num_layers=1\n",
        "        )\n",
        "\n",
        "        # Third LSTM layer\n",
        "        self.lstm3 = torch.nn.LSTM(\n",
        "            input_size=32,\n",
        "            hidden_size=352,\n",
        "            batch_first=True,\n",
        "            num_layers=1\n",
        "        )\n",
        "\n",
        "        self.h_proj_1_to_2 = torch.nn.Linear(16, 32)\n",
        "        self.c_proj_1_to_2 = torch.nn.Linear(16, 32)\n",
        "\n",
        "        self.h_proj_2_to_3 = torch.nn.Linear(32, 352)\n",
        "        self.c_proj_2_to_3 = torch.nn.Linear(32, 352)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        # # Initial hidden and cell states for lstm1\n",
        "        # h0 = torch.zeros(1, batch_size, 16).requires_grad_().to(device)\n",
        "        # c0 = torch.zeros(1, batch_size, 16).requires_grad_().to(device)\n",
        "        # x, (_, _) = self.lstm1(x, (h0, c0))\n",
        "\n",
        "        # # Initial hidden and cell states for lstm2\n",
        "        # h0 = torch.zeros(1, batch_size, 32).requires_grad_().to(device)\n",
        "        # c0 = torch.zeros(1, batch_size, 32).requires_grad_().to(device)\n",
        "        # x, (_, _) = self.lstm2(x, (h0, c0))\n",
        "\n",
        "        # # Initial hidden and cell states for lstm3\n",
        "        # h0 = torch.zeros(1, batch_size, 352).requires_grad_().to(device)\n",
        "        # c0 = torch.zeros(1, batch_size, 352).requires_grad_().to(device)\n",
        "        # x, (_, _) = self.lstm3(x, (h0, c0))\n",
        "\n",
        "\n",
        "        ###### parisa changes of model give h , c to new layaer\n",
        "\n",
        "        # Initial hidden and cell states for lstm1\n",
        "        h1 = torch.zeros(1, batch_size, 16).to(x.device)\n",
        "        c1 = torch.zeros(1, batch_size, 16).to(x.device)\n",
        "        x, (h1, c1) = self.lstm1(x, (h1, c1))\n",
        "\n",
        "        # Resize h1, c1 to match the input size of lstm2\n",
        "        h2 = self.h_proj_1_to_2(h1)\n",
        "        c2 = self.c_proj_1_to_2(c1)\n",
        "        x, (h2, c2) = self.lstm2(x, (h2, c2))\n",
        "\n",
        "        # Resize h2, c2 to match the input size of lstm3\n",
        "        h3 = self.h_proj_2_to_3(h2)\n",
        "        c3 = self.c_proj_2_to_3(c2)\n",
        "        x, (h3, c3) = self.lstm3(x, (h3, c3))\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_cHUoGUQu07"
      },
      "outputs": [],
      "source": [
        "class AE(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder().to(device)\n",
        "        self.decoder = decoder().to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLe9AlzgQu08"
      },
      "outputs": [],
      "source": [
        "class RUAD(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder().to(device)\n",
        "        self.fc1 = torch.nn.Linear(8,16)\n",
        "        self.fc2 = torch.nn.Linear(16,352)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        #print('LSTM out', x.shape)\n",
        "        x = self.fc1(x)\n",
        "        #print('DENSE 1', x.shape)\n",
        "        x = self.fc2(x)\n",
        "        #print('DENSE 2', x.shape)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrkfnO0P86Ot"
      },
      "outputs": [],
      "source": [
        "#### mine\n",
        "# class RUAD(torch.nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "\n",
        "#         self.encoder = encoder().to(device)\n",
        "#         self.fc1 = torch.nn.Linear(8,16)\n",
        "#         self.fc2 = torch.nn.Linear(16,352)\n",
        "\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.encoder(x)\n",
        "#         #print('LSTM out', x.shape)\n",
        "#         x = self.fc1(x)\n",
        "#         #print('DENSE 1', x.shape)\n",
        "#         x = self.fc2(x)\n",
        "#         #print('DENSE 2', x.shape)\n",
        "\n",
        "#         return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKtcGAZu8-5z"
      },
      "outputs": [],
      "source": [
        "### mine\n",
        "class RUAD(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder().to(device)\n",
        "        self.fc1 = torch.nn.Linear(8, 16)\n",
        "        self.fc2 = torch.nn.Linear(16, 8)\n",
        "        self.decoder = decoder().to(device)  # Adding the decoder to RUAD\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        # Passing through the fully connected layers   ----- new changes\n",
        "        # x = self.fc1(x)\n",
        "        # x = self.fc2(x)\n",
        "        # Passing the result through the decoder ------- end of new changes\n",
        "        x = self.decoder(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOfd8fWLQu08"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eZVG4bFQu08",
        "outputId": "d9c6da28-c848-472f-ee55-bc0bdb9cbe3a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RUAD(\n",
              "  (encoder): encoder(\n",
              "    (lstm1): LSTM(352, 32, batch_first=True)\n",
              "    (lstm2): LSTM(32, 16, batch_first=True)\n",
              "    (lstm3): LSTM(16, 8, batch_first=True)\n",
              "    (h_proj_1_to_2): Linear(in_features=32, out_features=16, bias=True)\n",
              "    (c_proj_1_to_2): Linear(in_features=32, out_features=16, bias=True)\n",
              "    (h_proj_2_to_3): Linear(in_features=16, out_features=8, bias=True)\n",
              "    (c_proj_2_to_3): Linear(in_features=16, out_features=8, bias=True)\n",
              "  )\n",
              "  (fc1): Linear(in_features=8, out_features=16, bias=True)\n",
              "  (fc2): Linear(in_features=16, out_features=8, bias=True)\n",
              "  (decoder): decoder(\n",
              "    (lstm1): LSTM(8, 16, batch_first=True)\n",
              "    (lstm2): LSTM(16, 32, batch_first=True)\n",
              "    (lstm3): LSTM(32, 352, batch_first=True)\n",
              "    (h_proj_1_to_2): Linear(in_features=16, out_features=32, bias=True)\n",
              "    (c_proj_1_to_2): Linear(in_features=16, out_features=32, bias=True)\n",
              "    (h_proj_2_to_3): Linear(in_features=32, out_features=352, bias=True)\n",
              "    (c_proj_2_to_3): Linear(in_features=32, out_features=352, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "model = RUAD()\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iL-wSQFNQu08"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)  ### adam ro bezar va bebin\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  ### adam ro bezar va bebin\n",
        "criterion = torch.nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVZcvSKOQu08",
        "outputId": "f65656b0-643a-47c4-919d-25d91ebad534"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "torch.Size([1, 20, 352])\n"
          ]
        }
      ],
      "source": [
        "for d in train_loader:\n",
        "    print(len(d[0]))\n",
        "    print(d[0][0].size())\n",
        "    break\n",
        "    ## batch size,(row count,column count) --> sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQEClIx2c8P4",
        "outputId": "8ce31014-4757-4373-9eaf-d74d2b9ac8ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RUAD(\n",
            "  (encoder): encoder(\n",
            "    (lstm1): LSTM(352, 32, batch_first=True)\n",
            "    (lstm2): LSTM(32, 16, batch_first=True)\n",
            "    (lstm3): LSTM(16, 8, batch_first=True)\n",
            "    (h_proj_1_to_2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (c_proj_1_to_2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (h_proj_2_to_3): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (c_proj_2_to_3): Linear(in_features=16, out_features=8, bias=True)\n",
            "  )\n",
            "  (fc1): Linear(in_features=8, out_features=16, bias=True)\n",
            "  (fc2): Linear(in_features=16, out_features=8, bias=True)\n",
            "  (decoder): decoder(\n",
            "    (lstm1): LSTM(8, 16, batch_first=True)\n",
            "    (lstm2): LSTM(16, 32, batch_first=True)\n",
            "    (lstm3): LSTM(32, 352, batch_first=True)\n",
            "    (h_proj_1_to_2): Linear(in_features=16, out_features=32, bias=True)\n",
            "    (c_proj_1_to_2): Linear(in_features=16, out_features=32, bias=True)\n",
            "    (h_proj_2_to_3): Linear(in_features=32, out_features=352, bias=True)\n",
            "    (c_proj_2_to_3): Linear(in_features=32, out_features=352, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tt9nQfh2Qu09",
        "outputId": "69fdf1dd-6b9e-4fdd-fdfd-d92080184244"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01, Loss: 0.0156\n",
            "Epoch: 02, Loss: 0.0138\n",
            "Epoch: 03, Loss: 0.0060\n",
            "Epoch: 04, Loss: 0.0160\n",
            "Epoch: 05, Loss: 0.0158\n",
            "Epoch: 06, Loss: 0.0070\n",
            "CPU times: user 26min 59s, sys: 12.6 s, total: 27min 11s\n",
            "Wall time: 27min 33s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "def train():\n",
        "    model.train()\n",
        "    for d in train_loader:\n",
        "        #print(type(d))\n",
        "        x = d[0][0].to(device)\n",
        "        y = d[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x)\n",
        "        loss = criterion(out[0][train_window-1], y[0][0])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return float(loss)\n",
        "\n",
        "for epoch in range(6):\n",
        "    loss = train()\n",
        "    print(f'Epoch: {epoch+1:02d}, Loss: {loss:.4f}')\n",
        "\n",
        "\n",
        "############ results\n",
        "########### result change layer 8 to 32\n",
        "# Epoch: 01, Loss: 0.0188\n",
        "# Epoch: 02, Loss: 0.0273\n",
        "# Epoch: 03, Loss: 0.0033\n",
        "# CPU times: user 6min 3s, sys: 3.62 s, total: 6min 6s\n",
        "# Wall time: 6min 12s\n",
        "\n",
        "########### result add hidden ayer 32\n",
        "# Epoch: 01, Loss: 0.0021\n",
        "# Epoch: 02, Loss: 0.0378\n",
        "# Epoch: 03, Loss: 0.0069\n",
        "# CPU times: user 7min 58s, sys: 4.28 s, total: 8min 2s\n",
        "# Wall time: 8min 11s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model with gpu\n",
        "# Epoch: 01, Loss: 0.0200\n",
        "# Epoch: 02, Loss: 0.0210\n",
        "# Epoch: 03, Loss: 0.0231\n",
        "# CPU times: user 13min 7s, sys: 14.9 s, total: 13min 22s\n",
        "# Wall time: 13min 5s\n",
        "\n",
        "########### #################result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu\n",
        "# Epoch: 01, Loss: 0.0089\n",
        "# Epoch: 02, Loss: 0.0483\n",
        "# Epoch: 03, Loss: 0.0035\n",
        "# CPU times: user 12min 38s, sys: 13.5 s, total: 12min 51s\n",
        "# Wall time: 12min 34s\n",
        "\n",
        "########### result of first ruad with adam optimizer\n",
        "# Epoch: 01, Loss: 0.0071\n",
        "# Epoch: 02, Loss: 0.0081\n",
        "# Epoch: 03, Loss: 0.0027\n",
        "# CPU times: user 14min 5s, sys: 6.38 s, total: 14min 12s\n",
        "# Wall time: 14min 20s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad and remove fully connected layers model with gpu and adam optimizer\n",
        "# Epoch: 01, Loss: 0.1494\n",
        "# Epoch: 02, Loss: 0.1621\n",
        "# Epoch: 03, Loss: 0.1690\n",
        "# CPU times: user 16min 19s, sys: 17.8 s, total: 16min 37s\n",
        "# Wall time: 16min 21s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu and add h,c to each layer\n",
        "# Epoch: 01, Loss: 0.0155\n",
        "# Epoch: 02, Loss: 0.0039\n",
        "# Epoch: 03, Loss: 0.0154\n",
        "# CPU times: user 13min 26s, sys: 8.53 s, total: 13min 35s\n",
        "# Wall time: 13min 46s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu and add h,c to each layer , epoch 6\n",
        "# Epoch: 01, Loss: 0.0155\n",
        "# Epoch: 02, Loss: 0.0039\n",
        "# Epoch: 03, Loss: 0.0154\n",
        "# Epoch: 04, Loss: 0.0054\n",
        "# Epoch: 05, Loss: 0.0114\n",
        "# Epoch: 06, Loss: 0.0200\n",
        "# CPU times: user 27min 26s, sys: 8.53 s, total: 27min 35s\n",
        "# Wall time: 26min 57s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu and add h,c to each layer , epoch 6 , window 10\n",
        "# Epoch: 01, Loss: 0.0155\n",
        "# Epoch: 02, Loss: 0.0039\n",
        "# Epoch: 03, Loss: 0.0154\n",
        "# Epoch: 04, Loss: 0.0054\n",
        "# Epoch: 05, Loss: 0.0114\n",
        "# Epoch: 06, Loss: 0.0200\n",
        "# CPU times: user 27min 26s, sys: 8.53 s, total: 27min 35s\n",
        "# Wall time: 26min 57s\n",
        "\n",
        "########### result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu and add h,c to each layer , epoch 6 , window 30\n",
        "# Epoch: 01, Loss: 0.0156\n",
        "# Epoch: 02, Loss: 0.0138\n",
        "# Epoch: 03, Loss: 0.0060\n",
        "# Epoch: 04, Loss: 0.0160\n",
        "# Epoch: 05, Loss: 0.0158\n",
        "# Epoch: 06, Loss: 0.0070\n",
        "# CPU times: user 26min 59s, sys: 12.6 s, total: 27min 11s\n",
        "# Wall time: 27min 33s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogU-wULvQu09"
      },
      "outputs": [],
      "source": [
        "def test(x):\n",
        "    model.eval()\n",
        "    x = x.to(device)\n",
        "    out = model(x)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AznBaZd9Qu09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b78dbc75-2f81-4f69-b5c7-e5506a754a96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n"
          ]
        }
      ],
      "source": [
        "X, y = next(iter(test_loader))\n",
        "#print(X.shape)\n",
        "print(len(X[0][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PD4G2hAlQu09"
      },
      "outputs": [],
      "source": [
        "out = test(X[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIJkCCKdQu0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf85a390-1e48-4c56-9642-a4abfbc8edfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 20, 352])\n"
          ]
        }
      ],
      "source": [
        "for d in test_loader:\n",
        "    print(d[0][0].size())\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbDh2hGvQu0-"
      },
      "outputs": [],
      "source": [
        "for d in test_loader:\n",
        "    x = d[0][0].to(device)\n",
        "    y = d[1].to(device)\n",
        "    out = model(x)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHNcfzkSQu0-"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error,roc_auc_score\n",
        "reconstruction = []\n",
        "loss = []\n",
        "#y_true = []\n",
        "for d in test_loader:\n",
        "    x = d[0][0]\n",
        "    y = d[1]\n",
        "    out = test(x)\n",
        "    reconstruction.append(out)\n",
        "    loss.append(mean_squared_error(out[0][train_window-1].detach().cpu().numpy(),y[0][0]))\n",
        "    #y_true.append(d[1].detach().cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LYPX4CKQu0-"
      },
      "outputs": [],
      "source": [
        "test_seq_label = create_data_seq(test_labels,train_window)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJaVsXaAQu0_"
      },
      "outputs": [],
      "source": [
        "temp_list = []\n",
        "for i in range(len(test_seq_label)):\n",
        "    temp = test_seq_label[i][1].type(torch.int64)\n",
        "    temp = temp.detach().cpu().numpy().tolist()\n",
        "    temp_list.append(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-WZzWbjQu0_"
      },
      "outputs": [],
      "source": [
        "y_true = []\n",
        "for i in range(len(temp_list)):\n",
        "    y_true.append(temp_list[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHHG9P2BQu0_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "7ec73bc9-7e5a-4eb9-af10-5b11238be02b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               loss    true_class\n",
              "count  10432.000000  10432.000000\n",
              "mean       0.016205      0.013133\n",
              "std        0.039524      0.113848\n",
              "min        0.001716      0.000000\n",
              "25%        0.005554      0.000000\n",
              "50%        0.008180      0.000000\n",
              "75%        0.015109      0.000000\n",
              "max        0.297797      1.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f70a3f70-2bd7-45f3-8ea6-61f6db0e4304\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>true_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10432.000000</td>\n",
              "      <td>10432.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.016205</td>\n",
              "      <td>0.013133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.039524</td>\n",
              "      <td>0.113848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.001716</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.005554</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.008180</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.015109</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.297797</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f70a3f70-2bd7-45f3-8ea6-61f6db0e4304')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f70a3f70-2bd7-45f3-8ea6-61f6db0e4304 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f70a3f70-2bd7-45f3-8ea6-61f6db0e4304');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5d3d8b1b-5768-475e-ad76-099665f389f9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5d3d8b1b-5768-475e-ad76-099665f389f9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5d3d8b1b-5768-475e-ad76-099665f389f9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"error_df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3688.2495728023982,\n        \"min\": 0.0017158999107778072,\n        \"max\": 10432.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.016204699873924255,\n          0.008180327713489532,\n          10432.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"true_class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3688.2120656395905,\n        \"min\": 0.0,\n        \"max\": 10432.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.013132668711656442,\n          1.0,\n          0.11384833856448454\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "error_df = pd.DataFrame({'loss': loss,\n",
        "                        'true_class': y_true})\n",
        "error_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9ilQ6bBQu0_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75d74f1a-50d8-4b5d-8e0e-d4c2886951f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9099321830808663"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(error_df['true_class'],error_df['loss'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#0.8765328998395648\n",
        "#0.8723729179726375    result of change hidden layer from 8 to 32\n",
        "#0.9065247187071686    result of add one layer 32 between encoder :)\n",
        "#0.904416749009233     result add hidden layer 32 to decoder too and add decoder to ruad model with gpu (this is pretty good)\n",
        "######0.9044238322407449    result add hidden layer 32 to decoder too and add decoder to ruad and remove fully connected layers model with gpu (this is pretty good)\n",
        "#0.836908594438955     result of first ruad with adam optimizer --> accuracy is lower than SGD so not good for this one at least\n",
        "#0.7857892667792901    result add hidden layer 32 to decoder too and add decoder to ruad and remove fully connected layers model with gpu and adam optimizer (not good)\n",
        "#0.9078464497072855    result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu and add h,c to each layer (gets better)\n",
        "#0.9111189026657741    result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu and add h,c to each layer (gets better), epoch 6\n",
        "#0.9078027534134614    result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu and add h,c to each layer (gets better), epoch 6 , window 10\n",
        "#0.9099321830808663    result add hidden layer 32 to decoder too and add decoder to ruad model and remove fully connected layers with gpu and add h,c to each layer (gets better), epoch 6 , window 30"
      ],
      "metadata": {
        "id": "0H5GYfJ0T5xq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}